% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% http://www.sciencemag.org/authors/preparing-manuscripts-using-latex
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{scicite}

\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{
\begin{quote} \bf}
{\end{quote}}



% Include your paper's title here

%\title{BEC.2: A graph clustering algorithm with good speed, good accuracy and intrinsic scale of description in the nPnB framework}
\title{BEC.2: A fast and relevant Multi-Scale\\ Graph Clustering algorithm  in nPnB framework}

% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{Bruno Gaume\\
\\
\normalsize{Complex Systems Institute of Paris Île-de-France (ISC-PIF, UAR3611), CNRS, France}\\
%\normalsize{$^\ast$To whom correspondence should be addressed; E-mail:  bruno.gaume@iscpif.org ; david@chavalarias.org}
\normalsize{bruno.gaume@iscpif.fr}
}

% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
%\usepackage[dvipsnames]{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%
\usepackage{lipsum}

\usepackage{euscript}
\usepackage{cancel}

\usepackage{wrapfig}



%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
%\theoremstyle{thmstylethree}%
%\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}%
\theoremstyle{definition}
\newtheorem{definition}{Definition}
%
\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads


\usepackage[textsize=tiny]{todonotes}
\usepackage{bm}
\newcommand{\bruno}[2][]
{\todo[color=cyan, #1]{#2}}

\newcommand{\ixandra}[2][]
{\todo[color=yellow, #1]{#2}}

\newcommand{\david}[2][]
{\todo[color=green, #1]{#2}}


\usepackage{multicol} % multicolonnage
\usepackage{subfigure}


\newcommand{\verteq}{\rotatebox{90}{$\,=$}}
\newcommand{\equalto}[2]{\underset{\scriptstyle\overset{\mkern4mu\verteq}{#2}}{#1}}

\usepackage{endnotes}


\usepackage{ulem}
\newcommand{\comRed}[1]{\textcolor{red}{[#1]}} % commentaires
\newcommand{\comBlue}[1]{\textcolor{blue}{[#1]}} % commentaires
\newcommand{\comGreen}[1]{\textcolor{green}{[#1]}} % commentaires
\newcommand{\comViolet}[1]{\textcolor{violet}{[#1]}} % commentaires
%
\newcommand{\N}[1]{\textcolor{blue}{#1}} % texte ajouté
%
\newcommand{\D}[1]{} % pour mieux lire le texte telle qu'il sera
% texte à retirer


%% END MACROS SECTION

\usepackage{url}
\usepackage{subfigure}
\usepackage{multirow}
%\usepackage[pdftex]{hyperref}
\newcommand{\Ned}{\mathbb{N}}
\usepackage{algorithm}
\usepackage{algpseudocode}

\def\myequationleft{\stepcounter{equation}\(\displaystyle}
\def\endmyequationleft{\hfill \hbox{\enspace(\theequation)}\)}
\usepackage{calligra}

\usepackage{scalerel,stackengine}
\stackMath
\newcommand\reallywidehat[1]{%
\savestack{\tmpbox}{\stretchto{%
  \scaleto{%
    \scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
    {\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
  }{\textheight}%
}{0.8ex}}%
\stackon[1pt]{#1}{\tmpbox}%
}
\parskip 1ex

\usepackage{tabularx}

\usepackage{endnotes}
\usepackage{mathtools}

\usepackage{lineno}
%%%%%%%%%%%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
%%%%%%%%%%%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

\begin{document}
%\linenumbers
\baselineskip16pt
\maketitle

\begin{sciabstract}
{\bf ABSTRACT:}


In a recent paper, a unified theoretical framework $nPnB$ is defined for the evaluation of graph clusterings with respect to the following two properties:

    \hspace{1cm}$\bf P_{DC}:$ Each community is {\it Densely Connected}; \vspace{-0.10cm}

    \hspace{1cm}$\bf P_{WC}:$  Communities are {\it Weakly Connected} to each other.

In this framework, the authors propose $BEC$, a graph clustering method which they show returns outperforming results than most state-of-the-art methods, i.e. better satisfying the two properties $P_{DC}$ and $P_{WC}$. However, this method is relatively slow and difficult to work on terrain graphs having more than a million nodes, the computation time is then counted in hours.

%This makes it difficult to apply $BEC$ to graphs resulting from statistical physics, biological data, complex systems or artificial intelligence where the number of nodes is very often greater than one million.

This makes it difficult to apply $BEC$ to real-world graphs or graphs resulting from artificial intelligence where the number of nodes is very often greater than one million.

To solve this difficulty we propose $BEC.2$ in the $nPnB$ framework, a new  graph clustering method.
%
We compare on different classical benchmarks the computation times and the quality of clusterings
returned by $BEC.2$, and $Louvain$ (one of the faster and most popular clustering method optimizing $Modularity$) as time base line, and $BEC$ as quality base line.

We show that $BEC.2$ remains slower than $Louvain$ but $100$ time faster than $BEC$ with computation time now counted in seconds and returning better or equivalent results.
\end{sciabstract}
\newpage
%
\section*{Introduction}
%\vspace{-0.10cm}
In the recent paper \cite{Gaume_BEC1_2025}, a unified theoretical framework $nPnB$ is defined for the evaluation of graph clusterings with respect to the following two properties:

    \hspace{1cm}$\bf P_{DC}:$ Each community is {\it Densely Connected}; \vspace{-0.10cm}

    \hspace{1cm}$\bf P_{WC}:$  Communities are {\it Weakly Connected} to each other.

In this theoretical framework a clustering of a graph is interpreted as a constrained binary classifier of node pairs intended to find the edges of the graph.
%
The authors propose a graph clustering method $BEC$ which they show returns outperforming results than most state-of-the-art methods (including $spectral~graph~clustering$, one of the best efficient state-of-the-art methods). % i.e. better satisfying the two properties $P_{DC}$ and $P_{WC}$.
However, this method is relatively slow and difficult to work on terrain graphs having more than a million nodes, the computation time is then counted in hours.

This makes it difficult to apply $BEC$ to real-world graphs or graphs resulting from artificial intelligence where the number of nodes is very often greater than one million.
To solve this difficulty we propose $BEC.2$ in the $nPnB$ framework, a new  graph clustering method.
%
We compare on different classical benchmarks the computation times and the quality of clusterings
returned by $BEC.2$, and $Louvain$ (one of the faster and most popular clustering method optimizing $Modularity$) as time base line, and $BEC$ as quality base line.
%
We show that $BEC.2$ remains slower than $Louvain$ but $100$ time faster than $BEC$ with computation time now counted in seconds and returning better or equivalent results.

In section \ref{nPnB} we present the graph clustering method $BEC$ in the $nPnB$ framework.
In section \ref{BEC.2} we define $BEC.2$, a method to find partitional clustering which we evaluate in section \ref{SecEval}.
In section \ref{SecOverlaps} we extend $BEC.2$ to clustering with overlaps
and conclude with perspectives in section \ref{Conclusion}.

This article follows the recent paper \cite{Gaume_BEC1_2025}
which defines the unified $nPnB$ theoretical framework for the evaluation of graph clusterings.
Therefore, in order to place the novelties of our present article in context, we use in sections \ref{nPnB}, \ref{BEC.2}, \ref{SecEval}, and \ref{Conclusion}, several passages that overlap with the article \cite{Gaume_BEC1_2025}.

\section{$BEC$ in the $nPnB$ framework \label{nPnB}}
%\vspace{-0.10cm}
\paragraph{Notation:} For a set of vertices $V$, let's note $\mathcal{P}(V)$ the subsets of $V$ and $\mathcal{P}_2(V)\subset \mathcal{P}(V)$ the pairs of elements from $V$. For a set $E\subset \mathcal{P}_2(V)$, $G=(V,E)$ defines a graph on $V$.
%
A set $\mathcal{C}\in \mathcal{P}(\mathcal{P}(V))$ such that $\mathcal{C}=\{C_i|~C_i \subset V, C_i \neq \emptyset, i \in I\}$ defines a
{\it clustering} on $V$ with {\it communities} $C_i$ if and only if $\bigcup_{i \in I} C_i=V$. It is a \textit{partitional clustering} if communities do not overlap ($\forall i\neq j \in I, C_i \cap C_j =\emptyset$), else it is an \textit{overlapping clustering}.
%
A {\it clustering of a graph} $G=(V,E)$ is a clustering on $V$.
%
Let's note $\EuScript{G}(V)=\{G |~G \text{ is a graph on } V\}$, and $\EuScript{C}(V)=\{\mathcal{C} |~\mathcal{C} \text{ is a clustering on } V\}$.

\noindent
\begin{definition} {\bf nPnB:}
Let a graph $G=(V,E)$. A $nPnB$ is a \textit{binary classifier of {\bf n}odes {\bf P}airs by {\bf n}odes {\bf B}locks}.
Instead of providing two complementary sets of nodes pairs as $Positive~Pairs$ and $Negative~Pairs$, a $nPnB$ classifier has to provide its predictions in the form of nodes blocks $\{C_i|~C_i \subset V, C_i \neq \emptyset, i \in I\}=\mathcal{C}$, a clustering such that $\{x,y\}$
is a $Positive~Pair$ if and only if $\exists C_i \in \mathcal{C}$ such $\{x,y\} \in C_i$, otherwise $\{x,y\} $ is a $Negative~Pair$. We will note $nPnB^{P}$ clusterings for which blocks are not overlapping and $nPnB^{O}$ those allowing overlap.
$\blacksquare$
\end{definition}

This can be formalized by defining $\widehat{\mathcal{C}}$
the {\it derived graph} from a clustering $\mathcal{C}$ using the three functions of Definition \ref{defUXI}.
%
\begin{definition} {\bf $\bf U(\cdot)$, $\bf \Xi(\cdot)$~and~$\bf \widehat{\cdot}$ :} Let a clustering $\mathcal{C}\in\EuScript{C}(V)$ of a graph $G=(V,E)\in\EuScript{G}(V)$. \label{defUXI}
\begin{equation}\label{EqU}
        U(\cdot):\mathcal{P}(\mathcal{P}(V)) \longrightarrow \mathcal{P}(V),~U(\mathcal{C})=\underset{{C_i\in\mathcal{C}}}{\bigcup}C_i
\end{equation}
%
\begin{equation}\label{EqXi}
        \Xi(\cdot):\mathcal{P}(\mathcal{P}(V)) \longrightarrow \mathcal{P}_2(V),~
        \Xi(\mathcal{C})= \underset{{C_i\in\mathcal{C}}}{\bigcup} \mathcal{P}_2({C_i})
\end{equation}

\begin{equation}\label{widehat}
        \widehat{\cdot}:\EuScript{C}(V)\longrightarrow \EuScript{G}(V),~\widehat{\mathcal{C}}=\big(U(\mathcal{C}),~\Xi(\mathcal{C})\big)
\end{equation}
$\blacksquare$
\end{definition}

\begin{figure}[h!] \centering
    \includegraphics[width=8cm]{fig/TPFPFN.pdf}
 \begin{itemize}
  \item[] $~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$
  ${\bf TP}=\Xi(\mathcal{C})~\bigcap~E \text{ is the set of True Positives}$;

  \item[] $~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$
  ${\bf TN}=\overline{\Xi(\mathcal{C})}~\bigcap~\overline{E} \text{ is the set of True Negatives}$;

  \item[] $~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$
  ${\bf FP}=\Xi(\mathcal{C})~\bigcap~\overline{E} \text{ is the set of False Postives}$;

  \item[] $~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$$~$
  ${\bf FN}=\overline{\Xi(\mathcal{C})}~\bigcap~E \text{ is the set of False Negatives}$;
  \normalsize
 \end{itemize}
%===========================================================================================================
\vspace{-0.30cm}
    \caption{{\bf Venn diagram of the capacities of the graph $\widehat{\mathcal{C}}=$$\big(U(\mathcal{C}),~\Xi(\mathcal{C})\big)$ to detect the edges of the graph $G=(V,E)$.} Interpreting graph clustering as binary classifier of node Pairs by node Blocks with to formula \ref{EqXi}.  \label{TPFPFN.FIG}}
\end{figure}

For any clustering $\mathcal{C}$ of a graph $G=(V,E)$ we can then compute the two classical metrics in diagnostic binary classification
$precision$ and $recall$, which assess the capacities of the graph $\widehat{\mathcal{C}}=\big(U(\mathcal{C}),~\Xi(\mathcal{C})\big)$ to detect the edges of the graph $G=(V,E)$ (see Fig. \ref{TPFPFN.FIG}).

\begin{definition} {\bf precision \& recall: } Let a clustering $\mathcal{C}\in\EuScript{C}(V)$ of a graph $G=(V,E)\in\EuScript{G}(V)$.
\begin{equation}\label{P(C,G)}
    P(\cdot,\cdot):\EuScript{G}(V)\times\EuScript{G}(V)\longrightarrow[0,1],~P(\widehat{\mathcal{C}},G)=\frac{|TP|}{|TP| + |FP|}=\frac{|\Xi(\mathcal{C}) \cap E|}{|\Xi(\mathcal{C})|}\\
\end{equation}
    {The {\bf precision} $P(\widehat{\mathcal{C}},G)$ is the probability that an edge drawn at random in $\Xi(\mathcal{C})$ (edges of the graph $\widehat{\mathcal{C}}$), actually belongs to $E$ (edges of the graph $G$)};
\begin{equation} \label{R(C,G)}
       R(\cdot,\cdot):\EuScript{G}(V)\times\EuScript{G}(V)\longrightarrow[0,1],~R(\widehat{\mathcal{C}},G)=P(G,\widehat{\mathcal{C}})=\frac{|TP|}{|TP| + |FN|}=\frac{|\Xi(\mathcal{C}) \cap E|}{|E|}
\end{equation}
      {The {\bf recall} $R(\widehat{\mathcal{C}},G)$ is the probability that an edge drawn at random in $E$ (edges of $G$), belongs to $\Xi(\mathcal{C})$ (edges of the graph $\widehat{\mathcal{C}}$)}.
$\blacksquare$
\end{definition}

The two properties $P_{DC}$ and $P_{WC}$ are then faithfully formalized by these two metrics $precision$ and $recall$ in the sense that:

 \noindent
 \hspace{0.2cm}$\bf \bullet~P_{DC}$: The more each module is densely connected, the higher the $precision$ and vice versa;

 \noindent
 \hspace{0.2cm}$\bf \bullet~P_{WC}$: The less the modules are connected to each other, the higher the $recall$ and vice versa.

Unless $G=(V,E)$ is reduced to a set of unconnected cliques, the following proposition
(see a proof in \cite{Gaume_BEC1_2025}) implies that there is no partitional clustering $\mathcal{C}$ such $P(\widehat{\mathcal{C}},G) = R(\widehat{\mathcal{C}},G) = 1$. The two metrics $precision$ and $recall$ are thus generally $antagonistic$.


\begin{proposition}
Let a partitional clustering $\mathcal{C} \in \EuScript{C}(V)$ of a graph $G=(V,E)\in \EuScript{G}(V)$.
Then:
  %\vspace{-0.10cm}
\begin{gather*}
\begin{array}{c}
  P(\widehat{\mathcal{C}},G) = R(\widehat{\mathcal{C}},G) = 1\\
  \Downarrow \\
  \text{The graph } G=(V,E) \text{ is reduced to a set of unconnected cliques.}
\end{array}
\end{gather*}
\end{proposition}

Since $precision$ and $recall$ are generally $antagonistic$, finding sets of non overlapping clusters on networks can be envisioned as a non trivial bi-objective task in the $nPnB^P$ framework.
%
Then to compare two clustering $\mathcal{C}_{1}$ and $\mathcal{C}_{2}$ such that $P(\widehat{\mathcal{C}_{1}},G) < P(\widehat{\mathcal{C}_{2}},G)$ and
$R(\widehat{\mathcal{C}_{2}},G) < R(\widehat{\mathcal{C}_{1}},G)$ or vice versa,
we need to specify our priorities in terms of $precision=\frac{|TP|}{|TP| + |FP|}$ faithfully formalizing $P_{DC}$ and $recall=\frac{|TP|}{|TP| + |FN|}$ faithfully formalizing $P_{WC}$.
This decision will depend on the needs of the modeler, from which she will define what constitutes a “good clustering”. It's only once a trade-off between $precision$ and $recall$ has been made that the modeler can assess the performances of different clustering methods.

The best known metric, the most used to evaluate binary classifier, with a hands $s$ on the trade-off between $precision$ and $recall$ is the F-score function:
$\frac{(1 + f(s)^2).|TP|}{(1 + f(s)^2).|TP| + f(s)^2.|FN| + |FP|}=$

\begin{equation}\label{FsPR}
    F_s(P,R)=\frac{(1+f(s)^2).(P.R)}{R+f(s)^2.P}
\end{equation}

\hspace{1.5cm} With $P=P(\widehat{\mathcal{C}},G)$, $R=R(\widehat{\mathcal{C}},G)$, $s\in[0,1]$, $f(s)=tan(\frac{\pi.s}{2})$ and $F_{1}(P,R) = R$.

\begin{itemize}
\item For $s=0$, only the $precision$ counts (i.e. the $P_{DC}$ property);

\item For $s=1$, only the $recall$ counts (i.e. the $P_{WC}$ property);

\item For $s=0.5$, $precision$ and $recall$ are of the same importance,
and can be interpreted as a `middle point of view’. It has both homogeneity and completeness, two fundamental properties for metrics intending compare clusterings \cite{Bcubed_Amigo_2009}. On contrary,  $precision$ has only homogeneity property --it is the archetypal metric of homogeneity-- and $recall$ has only completness property --it is the archetypal metric of completness.

 \item For $s\in~]0,~0.5[$: In order to improve $F_s(P,R)$, $precision$ need to be higher with a greater number of smaller and denser modules;

 \item For $s\in~]0.5,~1[$:  In order to improve $F_s(P,R)$, $recall$ need to be higher with a fewer number of bigger but less dense modules.
\end{itemize}

\vspace{-0.20cm}
\noindent
Thereby, the trade-off $s$ between $precision$ and $recall$ can be used to adjust the desired  {\it 'description scale'} (i.e. the size of communities).

\subsection{$nPnB$ as Unified Graph Clustering Framework \label{UnifiedGraphClusteringFramework}}
To simplify the notations, let’s note $\EuScript{P}(\mathcal{C}, G)=P(\widehat{\mathcal{C}},G)$; $\EuScript{R}(\mathcal{C}, G)=R(\widehat{\mathcal{C}},G)$
and $\EuScript{F}_{s}(\mathcal{C}, G)=F_{s}(P(\widehat{\mathcal{C}},G),R(\widehat{\mathcal{C}},G))$.

Interpreting graph clustering as $nPnB$, and using the $\Xi$ function to define the four metrics $TP, TN, FP, FN$ makes it possible to use these four metrics for clustering with and without overlaps, intrinsically against the original graph $G=(V,E)$ (as in Fig.~\ref{TPFPFN.FIG}) or extrinsicaly against a ground-truth $\mathcal{C}^{ref}_{G}$ of $G$, by replacing $E$, the edges of the graph $G$, by $\Xi(\mathcal{C}^{ref}_{G})$, the edges of the graph $\reallywidehat{\mathcal{C}^{ref}_{G}}$:
%
$\bf TP$$=\Xi(\mathcal{C})~\bigcap~\Xi(\mathcal{C}^{ref}_{G})$;
%
$\bf TN$$=\overline{\Xi(\mathcal{C})}~\bigcap~\overline{\Xi(\mathcal{C}^{ref}_{G})}$;
%
$\bf FP$$=\Xi(\mathcal{C})~\bigcap~\overline{\Xi(\mathcal{C}^{ref}_{G})}$;
%
$\bf FN$$=\overline{\Xi(\mathcal{C})}~\bigcap~\Xi(\mathcal{C}^{ref}_{G})$.

Let $\mathcal{C}$ and $\mathcal{C}^{ref}$ be two clusterings of a graph $G=(V,E)$.
The $nPnB$ framework makes it possible to measure the capacity of the graph $\widehat{\mathcal{C}}$ to detect the edges of the graph $\widehat{\mathcal{C}^{ref}}$.
%
If $\mathcal{C}^{ref}=E$ then $\widehat{\mathcal{C}^{ref}}=G$, it is an intrinsic measurement else it is extrinsic.
We can measure this capacity:

\vspace{-0.30cm}
\paragraph*{In the $\bf 2$-dimensional space $\bf precision \times recall$:}
with $\EuScript{P}(\mathcal{C}, \reallywidehat{\mathcal{C}^{ref}})$ and $\EuScript{R}(\mathcal{C}, \reallywidehat{\mathcal{C}^{ref}})$, where
$\EuScript{P}(\cdot,\cdot)$ the metric $precision$ faithfully formalizes the $P_{DC}$ property and
$\EuScript{R}(\cdot,\cdot)$ the metric $recall$ faithfully formalizes the $P_{WC}$ property.

\noindent
Then we can objectively conclude that $\mathcal{C}_2$ performs better or equal than $\mathcal{C}_1$ in regard of the gold standard $\mathcal{C}^{ref}$
{\bf iff }

%\vspace{-0.30cm}
\begin{equation*}
        \Big(\EuScript{P}(\mathcal{C}_2, \reallywidehat{\mathcal{C}^{ref}}), \EuScript{R}(\mathcal{C}_2, \reallywidehat{\mathcal{C}^{ref}})\Big)
\in
\Big[\EuScript{P}(\mathcal{C}_1, \reallywidehat{\mathcal{C}^{ref}}),1\Big] \times \Big[\EuScript{R}(\mathcal{C}_1, \reallywidehat{\mathcal{C}^{ref}}),1\Big]
\end{equation*}

\vspace{-0.30cm}
\paragraph*{In $\bf 1$-dimensional space:}
%
Since $precision$ and $recall$ are antagonistic, optimizing both of them is a multi-objective optimization that most of the time does not have a unique optimal solution as shown in \cite{Gaume_BEC1_2025}. If we cannot conclude one way or the other in the $2$-dimensional space $precision \times recall$,  the choice of a clustering can be reduced to $1$-dimensional space, provided that we combine:

\vspace{-0.30cm}
\begin{itemize}
 \item {\bf A subjective decision:} defining a trade-off between $precision$ and $recall$ through the choice of a {\it scale of description}
 $\sigma \in [0,1]$;
\item {\bf An objective methodology:} using then $\EuScript{F}_{\sigma}$ as objective criteria for the evaluation of graph clustering methods in regard of the subjective {\it scales of description} $\sigma$.
\end{itemize}
\normalsize

\vspace{-0.35cm}
\noindent
Then we can objectively conclude that $\mathcal{C}_2$ performs better or equal than $\mathcal{C}_1$ in regard of the gold standard $\mathcal{C}^{ref}$ under the subjective {\it scale of description} $\sigma$
{\bf iff}

%\vspace{-0.30cm}
\begin{equation*}
\EuScript{F}_{\sigma}(\mathcal{C}_1, \reallywidehat{\mathcal{C}^{ref}}) \leqslant \EuScript{F}_{\sigma}(\mathcal{C}_2, \reallywidehat{\mathcal{C}^{ref}})
\end{equation*}

\noindent
In a $1$-dimensional decision space,  it is necessary to choose a subjective $\sigma$ description scale \textit{before} being able to objectively compare two clusterings with $\EuScript{F}_{\sigma}$.


\subsection{$BEC$ a clustering family algorithms based on $\EuScript{F}_{s}$ optimization \label{secBEC}}
%
We present in this section $BEC^{s}$ (Binary Edges Classifier) the clustering family detreminist algorithms proposed in \cite{Gaume_BEC1_2025} to optimize $\EuScript{F}_{s}$ in regard of a graph $G=(V,E)$.

The trivial clustering $\mathcal{C}=\{\{i\}|~i\in V\}$ where each vertice is assigned to its own cluster is a partitional clustering.
%
Then $\forall s \in [0,1]$ its $\EuScript{F}_{s}$ score $\EuScript{F}_{s}(\mathcal{C},G)=F_{s}(P(\widehat{\mathcal{C}}, G),R(\widehat{\mathcal{C}}, G))=0$ since its $recall$ $R(\widehat{\mathcal{C}}, G)=0$.

$BEC^{s}$ improve this trivial clustering by an agglomeration process that reviews each edge of $G$ only once and merges the clusters of their vertices if this operation does not decrease  $\EuScript{F}_{s}(\mathcal{C},G)$
(see \cite{Gaume_BEC1_2025} for pseudo-code).

The order in which edges are traversed is essential. The proposed algorithm involves choosing a ranking function on $E$ derived from a similarity measure $Sim(G, x, y)$ on the vertices of $G$. Edges $\{x,y\}\in E$ are then reviewed by descending order of $Sim(G, x, y)$.

The quality of the process depends on the choice of the similarity measure, and there is no guarantee of obtaining an optimal clustering
$\mathcal{C}^{*}$ such $\EuScript{F}_{s}(\mathcal{C}^{*},G)$ is maximal.
$BEC^{s}$ use the similarity $cos$ as ranking function:
\begin{equation*}%
\label{SimCos}
cos(G=(V,E),x,y)=Cosinus\big(\overrightarrow{(P^2_G(x{\rightsquigarrow}x), P^2_G(x{\rightsquigarrow}y))}, \overrightarrow{(P^2_G(y{\rightsquigarrow}x), P^2_G(y{\rightsquigarrow}y))}\big)
\end{equation*}
\noindent
\begin{itemize}
 \item[] Where: $P^{\lambda}_{G}(x{\rightsquigarrow}y)$ is the probability that a random walker wandering on the graph $G$ through its edges, reaches the node $y$ after $\lambda$ steps starting from the node $x$.
\end{itemize}

\noindent
In the $nPnB$ framework, using the similarity $cos$ to rank the edges ($cos$ ranking), the partitional clusterings returned by $BEC^{s}$ outperform most state-of-the-art partitional clusterings methods (including $spectral~graph~clustering$, one of the best performing state-of-the-art methods) i.e. better satisfying the two properties $P_{DC}$ and $P_{WC}$ (see \cite{Gaume_BEC1_2025}).

For clarity and readability we will denote in the following
$BEC^{s}$ as $MER.cos^{s}$ (cluster {\bf MER}ging strategy with edge ranking by $\bf cos$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{$BEC.2$ to optimize $\EuScript{F}_{s}$ better and faster \label{BEC.2}}
In this section we propose a new clustering family algorithms based on $\EuScript{F}_{s}$ optimization, faster an more relevant than the family $MER.cos^{s}$.

\subsection{Replace $cos~ranking$ by $random~ranking$ \label{Replace}}
Most of the time consumed by $MER.cos^{s}$ is spent calculating the similarities $cos(G=(V,E), x, y)$ for all $\{x,y\} \in E$.
The worst-case time complexity to compute edges $cos~ranking$ is $O(|V|^2)$, which can consume many time with large graphs.
So to save computation time let's start by examining how the $MER.rand^{s}$ method reacts,
where $MER.rand^{s}$ has the same merging clusters strategy that $MER.cos^{s}$ but with a edges $random~ranking$ replacing the edges $cos~ranking$.
%Note that $MER.rand$ is then like $Louvain$ a non-deterministic graph clustering method.

To illustrate how the $MER.rand^{s}$ method reacts, we compare $MER.rand^{s}$, with $MER.cos^{s}$ (outperforming state-of-the-art partitional clusterings methods in the $nPnB$ framework \cite{Gaume_BEC1_2025}) and $Louvain$ ~\cite{1742-5468-2008-10-P10008} (one of the faster and most popular clustering method optimizing $Modularity$ \cite{Newman_2004}).

We compare these methods on a standard real-world graph $G_{em}=(V_{em},E_{em})$ frequently used for benchmarking \cite{10.1145/3097983.3098069}. $G_{em}$ describes e-mail data from a large research institution composed of a set $V_{em}$ of employees. This is a little graph as standard benchmark with $|V_{em}|=1,005,~|E_{em}|=16,064$. The graph contains an undirected edge $\{i,j\}$ if employee $i$ and employee $j$ have exchanged at least one e-mail either way.
The dataset\footnote{Available at \url{https://snap.stanford.edu/data/email-Eu-core.html}} on which $G_{em}$ is build, also contains the list of the 42 departments of the research institute that are often considered as a `ground-truth' partition $\mathcal{C}_{Dep}$ on $G_{em}$.

We add to this clusterings comparison the Oracle method $met_{Dep}$ returning the `ground-truth' partition itself ($\mathcal{C}=\mathcal{C}_{Dep} \in \mathcal{P}(\mathcal{P}(V))$) and the omniscient overlapping clustering method $met_{E}$ returning the edges of graph itself ($\mathcal{C}=E \in \mathcal{P}(\mathcal{P}(V))$).

Fig.~\ref{FigPrecRecPlane_email} displays methods applied to $G_{em}$ on the $precision \times recall$ plane, and Fig. \ref{FigScaleFamily_email} displays the performances of each clustering method under the scale of description $\sigma \in [0,1]$.

\noindent
{\bf $\blacksquare$ I: We can see in Fig. \ref{FigPrecRecPlane_email}} that generally
$\EuScript{P}(MER.rand^{s}(G_{em}), G_{em})$ $\not\approx$ $\EuScript{P}(MER.cos^{s}(G_{em}), G_{em})$ and $\EuScript{R}(MER.rand^{s}(G_{em}), G_{em})$ $\not\approx$ $\EuScript{R}(MER.cos^{s}(G_{em}), G_{em})$.

\noindent
{\bf $\blacksquare$ II: We can see in Fig. \ref{FigScaleFamily_email}} that
$\forall \sigma \in [0,1]$, $\EuScript{F}_{\sigma}(MER.rand^{s=\sigma}(G_{em}), G_{em})$ $\leqslant$
%
$\EuScript{F}_{\sigma}(MER.cos^{s=\sigma}(G_{em}), G_{em})$.

\noindent
Points {\bf I} and {\bf II} show that with the merging cluster strategy $MER.rank^{s}$, $precision$, $recall$ and $\EuScript{F}_{\sigma}$ of the retrurned clusterings are sensitive to the ranking edges $rank$ which needs a well adapted ranking edge (for example as $cos$ ranking) to return relevant results (see \cite{Gaume_BEC1_2025} for more details).

\newpage
\begin{figure}[h!] \centering
     \includegraphics[width=16cm]{fig/BEC2_FigPrecRecPlane_email+square.png}
 %===========================================================================================================
 \caption{{\bf Performances in the $\bf 2$-dimensional space $precision \times recall$ of clustering methods when applied to the e-mail graph $\bf G_{em}$.} The Oracle method $met_{Dep}$ and the Omniscient method $met_E$ are highligthed in red.
 For each non deterministic methode ($Louvain$, $MER.rand^{s}$ and $MMM.rand^{s}$),
    the $precision$ and the $recall$ are the averages computed over $100$ runing (the standard deviations are always lower than $0.02$).
    \label{FigPrecRecPlane_email}}
 \end{figure}

% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\begin{figure}[h!] \centering
     \includegraphics[width=16cm]{fig/BEC2_FigScaleFamily_email.png}
 %===========================================================================================================
\caption{{\bf Performances $\EuScript{F}_{\sigma}(\clubsuit,G_{em})$ of clustering methods
$method(G_{em})=\clubsuit$ under the description scale $\sigma$.}
The Oracle method $met_{Dep}$ and the Omniscient method $met_E$ are highligthed in red.
 For each non deterministic $method \in \{Louvain,~MER.rand^{s=\sigma},~ MMM.rand^{s=\sigma}\}$,
    the Fscores $\EuScript{F}_{\sigma}$ are the averages computed over $100$ runing (the standard deviations are always lower than $0.01$).
    \label{FigScaleFamily_email}}
\end{figure}
\newpage

\subsection{$Moving~nodes$ and $Merging~clusters$}
In this section we propose $MMM.ind^{s}$ ({\bf M}oving nodes then  {\bf M}erging clusters then {\bf M}oving nodes strategy with index nodes ranking)
a new cluster construction strategy to optimize $\EuScript{F}_{s}(\mathcal{C},G=(V,E))$. General principle of $MMM.ind^{s}$ is as follows:

\newpage
\noindent
\rule{16cm}{0.05cm}

% \noindent
% {\bf Algorithm: $\mathcal{C} = MMM.ind^{s}(G, \varepsilon)$:} To find Partitional Clustering in $nPnB$ framework
%
% \vspace{-0.2cm}
% \noindent
% \rule{16cm}{0.025cm}
%
% \noindent
% {\bf Input:} $G = (V, E) \in \EuScript{G}(V)$
%
% \noindent
% \hspace{1.3cm}$s \in [0, 1]$
%
% \noindent
% \hspace{1.3cm}$\varepsilon \in [0, 1]$ (Default $\varepsilon=0.01$)
%
% \noindent
% {\bf Output:}  $\mathcal{C} \in \EuScript{C}(V)$ such $\forall C_i\neq C_j \in \EuScript{C}(V), C_i \cap C_j =\emptyset$
% \begin{itemize}
%  \item[{\bf }] {\bf Initialization:} Build the trivial clustering where each node is assigned to its own cluster: $\mathcal{C} \leftarrowtail \{\{i\}|~i\in V\}$;
%
%  \item[{\bf (1)}] {\bf Move Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by moving $i$ into the cluster of one of its neighbors or by isolation in its own cluster. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
%
%  \item[{\bf }] {\bf While:} If total improvement during the loop (1) is greater than $\varepsilon$, then restart the loop (1);
%
%  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  \item[{\bf (2)}] {\bf Merge Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by merging cluster of $i$ with the cluster of one of its neighbors. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
%
%  \item[{\bf }] {\bf While:} If at least one edit during the loop (2), then restart the loop (2);
%
%   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  \item[{\bf (3)}] {\bf Move Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by moving $i$ into the cluster of one of its neighbors or by isolation in its own cluster. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
%
%  \item[{\bf }] {\bf While:} If total improvement during the loop (3) is greater than $\varepsilon$, then restart the loop (3);
%
%
%  \item[{\bf }] {\bf Return:} Return the curent clustering $\mathcal{C}$.
% \end{itemize}
% \vspace{-0.5cm}
% \noindent
% \rule{16cm}{0.025cm}


\noindent
{\bf Algorithm: $\mathcal{C} = MMM.ind^{s}(G, \varepsilon)$:} To find Partitional Clustering in $nPnB$ framework

\vspace{-0.2cm}
\noindent
\rule{16cm}{0.025cm}

\noindent
{\bf Input:} $G = (V, E) \in \EuScript{G}(V)$

\noindent
\hspace{1.3cm}$s \in [0, 1]$ $\big($To find a partitional clustering $\mathcal{C}$ optimizing $\EuScript{F}_{s}(\mathcal{C},G)$$\big)$

\noindent
\hspace{1.3cm}$\varepsilon \in [0, 1]$ $\big($Default $\varepsilon=0.01$$\big)$

\noindent
{\bf Output:}  $\mathcal{C} \in \EuScript{C}(V)$ such $\forall C_i\neq C_j \in \EuScript{C}(V), C_i \cap C_j =\emptyset$
\begin{itemize}
 \item[{\bf }] {\bf Initialization:} Build the trivial clustering where each node is assigned to its own cluster: $\mathcal{C} \leftarrowtail \{\{i\}|~i\in V\}$;

 \item[] {\bf Do$_1$}
    \vspace{-0.40cm}
    \begin{itemize}
    \item[] {\bf (1) Move Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by moving $i$ into the cluster of one of its neighbors or by isolation in its own cluster. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
    \end{itemize}
    \vspace{-0.40cm}
 \item[{\bf }] {\bf While} (Total improvement during Move Loop (1) is greater than $\varepsilon$);

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item[] {\bf Do$_2$}
  \vspace{-0.40cm}
    \begin{itemize}
    \item[] {\bf (2) Merge Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by merging cluster of $i$ with the cluster of one of its neighbors. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
    \end{itemize}
    \vspace{-0.40cm}
 \item[{\bf }] {\bf While} (At least one edit is done during Merge Loop (2));

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \item[] {\bf Do$_3$}
    \vspace{-0.40cm}
    \begin{itemize}
    \item[] {\bf (3) Move Loop on $\bf i \in V$:} For each node $i$, improve the curent clustering $\mathcal{C}$ by moving $i$ into the cluster of one of its neighbors or by isolation in its own cluster. If no edit can improve $\EuScript{F}_{s}(\mathcal{C},G)$ then we examine the next node, else we adopt the edit that most improves $\EuScript{F}_{s}(\mathcal{C},G)$;
    \end{itemize}
    \vspace{-0.40cm}
 \item[{\bf }] {\bf While} (Total improvement during Move Loop (3) is greater than $\varepsilon$);


 \item[{\bf }] {\bf Return:} Return the curent clustering $\mathcal{C}$.
\end{itemize}
\vspace{-0.5cm}
\noindent
\rule{16cm}{0.025cm}

\vspace{0.20cm}
The input variable $\varepsilon$ is only used to speed up the calculation time in {\bf Do$_1$} and {\bf Do$_3$}.
With $\varepsilon=0$ the computation time is longer for results of quality only slightly better than with $\varepsilon=0.01$.

$MMM.ind$ can have remorses, meaning that in {\bf Do$_1$} and {\bf Do$_3$}, a move from a vertex to a module can be undone later (e.g. in Tab. \ref{tigraph}: in {\bf Do$_1$}, edit [b] is subsequently undone by edits [c] and [d]).
%
Conversely, $Merge.rank$ is remorseless, meaning that when two modules are merged, this merge cannot be undone later (e.g., edit [a] in Tab. \ref{tigraph}). This is why $Merge$ is very sensitive to rank edges.
%

\begin{table}[!ht]
\centering
\normalsize
\begin{tabular}{| l | l |}
\hline
\multicolumn{2}{|c|}{\includegraphics[width=6cm]{fig/tigraph.png}}\\

\hline
$\bf Merge.rank^{s=0.5}$ with ranked edge $RE:$& $\bf MMM.ind^{s=0.5}$ with ranked vertices $RV:$\\

\small $[(0,1),(2,3),(4,5),(0,2),(1,5),(0,3),(1,4)]$\normalsize & \small $[0,1,2,3,4,5]$\normalsize\\
\hline
$\bullet$ Init: $\mathcal{C}\leftarrowtail\big\{\{0\}, \{1\}, \{2\}, \{3\}, \{4\}, \{5\}\big\}$ & $\bullet$ Init: $\mathcal{C}\leftarrowtail\big\{\{0\}, \{1\}, \{2\}, \{3\}, \{4\}, \{5\}\big\}$ \\
$\bullet$ Merge Loop with $RE$: & $\bullet$ Move Loop (1) with $RV$: \\

\hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2\}, \{3\}, \{4\}, \{5\}\big\}$ \color{red}{[a]}& \hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2\}, \{3\}, \{4\}, \{5\}\big\}$ \color{red}{[b]}\\

\hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2,3\}, \{4\}, \{5\}\big\}$ & \hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2,3\}, \{4\}, \{5\}\big\}$\\

\hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2,3\}, \{4,5\}\big\}$ & \hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1\}, \{2,3\}, \{4,5\}\big\}$\\

\hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,1,2,3\}, \{4,5\}\big\}$ & $\bullet$ Move Loop (1) with $RV$:\\

$\bullet$ Return $\mathcal{C}$ & \hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{1\}, \{0,2,3\}, \{4,5\}\big\}$ \color{red}{[c]}\\

& \hspace{0.5cm} $\mathcal{C}\leftarrowtail\big\{\{0,2,3\}, \{1, 4,5\}\big\}$ \color{red}{[d]}\\
                              & $\bullet$ Move Loop (1) with $RV$: (no edit)\\
                              & $\bullet$ Merge Loop (2) with $RV$: (no edit)\\
                              & $\bullet$ Move Loop (3) with $RV$: (no edit)\\
                              & $\bullet$ Return $\mathcal{C}$\\
\hline
$\mathcal{C}=\big\{\{0,1,2,3\}, \{4,5\}\big\}$ & $\mathcal{C}=\big\{\{0,2,3\}, \{1,4,5\}\big\}$\\
$\EuScript{P}(\mathcal{C},G_{toy})=0.71$, $~$
$\EuScript{R}(\mathcal{C},G_{toy})=0.71$
&
$\EuScript{P}(\mathcal{C}, G_{toy})=1.00$, $~$
$\EuScript{R}(\mathcal{C}, G_{toy})=0.86$\\

$\bf \EuScript{F}_{s=0.5}(\mathcal{C}, G_{toy})=0.71$
&
$\bf \EuScript{F}_{s=0.5}(\mathcal{C}, G_{toy})=0.92$\\
\hline
\end{tabular}
    \caption{{\bf Edits of $Merge.rank^{s=0.5}$ and $MMM.ind^{s=0.5}$ on the toy graph $G_{toy}$.}\label{tigraph}}
\end{table}
\normalsize

\newpage

With $MMM.ind^{s}$ in the loops (1), (2), (3), the nodes are traversed according to ranking $ind$, the order induced by their indices.
But the nodes could just as easily be traversed according to a random ranking  $rand$, we will note then such method $MMM.rand^{s}$ ({\bf M}oving nodes then  {\bf M}erging clusters then {\bf M}oving nodes strategy with random nodes ranking).
Note that, unlike the $MMM.rand^{s}$ method, the $MMM.ind^{s}$ method has the avantage to be deterministic.

\noindent
{\bf $\blacksquare$ III: We can see in Fig. \ref{FigPrecRecPlane_email}} that for all $s\in [0,1]$:
$\EuScript{P}(MMM.rand^{s}(G_{em}), G_{em}) \approx \EuScript{P}(MMM.ind^{s}(G_{em}), G_{em})$ and $\EuScript{R}(MMM.rand^{s}(G_{em}), G_{em}) \approx \EuScript{R}(MMM.ind^{s}(G_{em}), G_{em})$.

\noindent
{\bf $\blacksquare$ IV: We can see in Fig. \ref{FigScaleFamily_email}} that for all $\sigma$:
%
$\EuScript{F}_{\sigma}(Louvain(G_{em}), G_{em})$ $\leqslant$ $\EuScript{F}_{\sigma}(MER.rand^{s=\sigma}(G_{em}), G_{em})$ $\leqslant$
$\EuScript{F}_{\sigma}(MER.cos^{s=\sigma}(G_{em}), G_{em})$ $\leqslant$ $\EuScript{F}_{\sigma}(MMM.rand^{s=\sigma}(G_{em}), G_{em})$ $\approx$
$\EuScript{F}_{\sigma}(MMM.ind^{s=\sigma}(G_{em}), G_{em})$.

\noindent
{\bf $\blacksquare$ V: We can see in Tab. \ref{tab_sur_determ}} that $\forall s \in [0,1]$, the averages of $\EuScript{F}_{0.5}(MMM.rand^{s}(G_{em})),\widehat{MMM.ind^{s}(G_{em})})$, over these $100$ runings of $MMM.rand^{s}(G_{em})$
are always equal or greater than $0.66$ with standarts deviation always equal or smaller than $0.08$. That is, the hundred different executions of $MMM.rand^{s}(G_{em})$ return clusterings that all {\it 'look like'} $MMM.ind^{s}(G_{em})$.
\begin{table}[!ht]
\centering
\begin{tabular}{| l  c | c | l  c |  }
  \cline{1-2} \cline{4-5}
  {\bf methode} & $\bf \stackrel{}{\overline{\EuScript{F}_{0.5}}~(std)}$ &~~~~& {\bf methode} & $\bf \stackrel{}{\overline{\EuScript{F}_{0.5}}~(std)}$  \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.10}$& $0.27(0.03)$ &~~~~& $MMM.rand^{s=0.10}$ & $0.66(0.04)$\\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.30}$& $0.15(0.02)$ &~~~~& $MMM.rand^{s=0.30}$ & $0.82(0.03)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.50}$& $0.23(0.02)$ &~~~~& $MMM.rand^{s=0.50}$ & $0.90(0.03)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.70}$& $0.26(0.03)$ &~~~~& $MMM.rand^{s=0.70}$ & $0.71(0.08)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.90}$& $0.69(0.03)$ &~~~~& $MMM.rand^{s=0.90}$ & $0.95(0.03)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.99}$& $1.00(0.00)$ &~~~~& $MMM.rand^{s=0.99}$ & $1.00(0.00)$ \\
  \cline{1-2} \cline{4-5}
\end{tabular}
\bigskip
    \caption{{\bf $\bf \overline{\EuScript{F}_{0.5}}$ and standart deviation over $\bf 100$ pairs of clusterings:} In Fig. \ref{FigPrecRecPlane_email} and \ref{FigScaleFamily_email}, for each non deterministic methode $met \in \{MER.rand,~ MMM.rand\}$, the $y$-values are the averages computed over $100$ runing.
    In the first column we then calculate the average of $\EuScript{F}_{0.5}(MER.rand(G_{em})),\widehat{MER.cos(G_{em})})$ over these $100$ runings of $MER.rand(G_{em})$ and the standard deviations. We do the same thing with $MMM.rand$ and $MMM.ind$ in the second column.  \label{tab_sur_determ}}
\end{table}

\noindent
{\bf $\blacksquare$ VI: We can see in Tab. \ref{tabcois}} that $\forall s \in [0,1]$, over the $4950$ pairs $\{\mathcal{C}_1, \mathcal{C}_2\}$ such that $\mathcal{C}_1$ is returned by one of $100$ runings of $MMM.rand^{s}(G_{em})$ and $\mathcal{C}_2$ is returned by an other of the $100$ runings of $MMM.rand^{s}(G_{em})$, then the averages of $\EuScript{F}_{0.5}(\mathcal{C}_1,\widehat{\mathcal{C}_2})$ are always equal or gerater than $0.63$ with standarts deviation always equal or smaller than $0.05$. The hundred different runings of $MMM.rand^{s}{s}(G_{em})$ return clusterings that {\it 'look alike'}.
That is, if two graphs $G_1$ and $G_2$ are isomorphic, then $\forall s \in [0,1]$ the two clustrings $\mathcal{C}_1=MMM.rand^{s}(G_1)$ and $\mathcal{C}_2=MMM.rand^{s}(G_2)$ are not necessarily equal but they {\it 'look alike'} in the sense that
$\EuScript{F}_{0.5}(\mathcal{C}_1,\widehat{\mathcal{C}_2)}$ is strong.

\begin{table}[!ht]
\centering
\begin{tabular}{| l  c | c | l  c |  }
  \cline{1-2} \cline{4-5}
  {\bf methode} & $\bf \stackrel{}{\overline{\EuScript{F}_{0.5}}~(std)}$ &~~~~& {\bf methode} & $\bf \stackrel{}{\overline{\EuScript{F}_{0.5}}~(std)}$  \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.10}$& $0.17~(0.02)$ &~~~~& $MMM.rand^{s=0.10}$ & $0.63~(0.04)$\\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.30}$& $0.25~(0.02)$ &~~~~& $MMM.rand^{s=0.30}$ & $0.85~(0.03)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.50}$& $0.26~(0.02)$ &~~~~& $MMM.rand^{s=0.50}$ & $0.90~(0.04)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.70}$& $0.34~(0.04)$ &~~~~& $MMM.rand^{s=0.70}$ & $0.69~(0.05)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.90}$& $0.78~(0.04)$ &~~~~& $MMM.rand^{s=0.90}$ & $0.94~(0.04)$ \\
  \cline{1-2} \cline{4-5}
  $MER.rand^{s=0.99}$& $1.00~(0.00)$ &~~~~& $MMM.rand^{s=0.99}$ & $1.00~(0.00)$ \\
  \cline{1-2} \cline{4-5}
  $Louvain$& $0.78(0.08)$& \multicolumn{3}{c}{}\\
  \cline{1-2}
\end{tabular}
\bigskip
    \caption{{\bf $\bf \overline{\EuScript{F}_{0.5}}$ and standart deviation over $\bf 4950$ pairs of clusterings:} In Fig. \ref{FigPrecRecPlane_email} and \ref{FigScaleFamily_email}, for each non deterministic methode $met \in \{Louvain,~MER.rand,~ MMM.rand\}$,
    the $y$-values are the averages computed over $100$ runing.
    For each of these methods $met$, there are therefore $\frac{100\times99}{2}=4950$ pairs $\{\mathcal{C}_1, \mathcal{C}_2\}$ such that $\mathcal{C}_1$ is returned by a runing of $met(G_{em})$ and $\mathcal{C}_2$ is returned by an other runing of $met(G_{em})$. We then calculate the average of $\EuScript{F}_{0.5}(\mathcal{C}_1,\widehat{\mathcal{C}_2})$ over these $4950$ pairs $\{\mathcal{C}_1, \mathcal{C}_2\}$ and the standard deviations. \label{tabcois}}
\end{table}

\noindent
Points {\bf III-VI} show that with the $MMM$ strategy, $precision$, $recall$ and $\EuScript{F}_{\sigma}$ of the retrurned clusterings are only very slightly sensitive to the order in which the nodes are traversed in loops (1), (2) and (3).
%
Furthermore we will see in the section \ref{SecEval} that $MMM.ind$ is faster than $MER.cos$.

\subsubsection{$MMM.ind$ is able to outperform $met_{Dep}$}
In Fig. \ref{FigPrecRecPlane_email}, all methods in the yellow square intrinsically objectively outperforms $met_{Dep}$ (returning $\mathcal{C}_{Dep}$ often considered as a {\it 'ground-truth'} of the graph $G_{em}$).
Indeed any method $method$ in the yellow square is such
$\EuScript{P}(met_{Dep}, G_{em}) < \EuScript{P}(method(G_{em}), G_{em})$ and in same time
$\EuScript{R}(met_{Dep}, G_{em}) < \EuScript{R}(method(G_{em}), G_{em})$.

Since both methods $MMM.ind^{0.50}$ and $MMM.ind^{0.70}$ are in the yellow square, we can therefore objectively state that these two methods outperform $met_{Dep}$.
%
This means that the two derived graphs $\reallywidehat{MMM.ind^{0.50}(G_{em})}$ and $\reallywidehat{MMM.ind^{0.70}(G_{em})}$
objectively detect the edges of $G_{em}$ better than the derived graph $\reallywidehat{\mathcal{C}_{Dep}}$ from the {\it 'ground-truth'} $\mathcal{C}_{Dep}$.

To be able to compare objectively the methods outside the yellow and purple rectangles
we need to subjectively choose before a trade-off $\sigma$ between $precision$ and $recall$ relatively to what we will expect betwwen $P_{DC}$ and $P_{WC}$ propeties from clustering of $G_{em}$.

For example with the subjective trade-off $\sigma=0.3$ then $\EuScript{F}_{0.3}(Louvain(G_{em}),G_{em})=0.15<0.25=\EuScript{F}_{0.3}(met_{Dep},G_{em})$
while with the subjective trade-off $\sigma=0.8$ then $\EuScript{F}_{0.8}(Louvain(G_{em}),G_{em})=0.43>0.32=\EuScript{F}_{0.8}(met_{Dep},G_{em})$.

%\newpage
\section{Evaluation\label{SecEval}}
In the following we will note $BEC^s$ for $MER.cos^s$ and $BEC.2^s$ for $MMM.ind^s$

$Louvain$ is one of the fastest state-of-the-art methods, and it is shown in \cite{Gaume_BEC1_2025} that $BEC$ outperform state-of-the-art partitional clusterings methods in the $nPnB$ framework.
%
Also, in this section we compare on different graphs the computation times and the quality of clusterings returned by $BEC.2$, and $Louvain$ as time base line and $BEC$ as quality base line.

\subsection{Evaluation on terrain graphs\label{SubSecEvalRG}}
\begin{table}[!ht]
\footnotesize
\centering
\begin{tabular}{| l | c c c  | c c c | c c c | c c c | c c c | }
   \hline   & \multicolumn{3}{c|}{\bf $\bf G_{dblp}$}   & \multicolumn{3}{c|}{\bf $\bf G_{amazon}$}   & \multicolumn{3}{c|}{\bf $\bf G_{retweet}$}   & \multicolumn{3}{c|}{\bf $\bf G_{youtube}$}   & \multicolumn{3}{c|}{\bf $\bf G_{WikiTalk}$}\\

   & \multicolumn{3}{c|}{\bf $|V|=317\,080$}   & \multicolumn{3}{c|}{\bf $|V|=334\,863$}   & \multicolumn{3}{c|}{\bf $|V|=1\,112\,702$}   & \multicolumn{3}{c|}{\bf $|V|=1\,134\,890$}   & \multicolumn{3}{c|}{\bf $|V|=2\,516\,783$}\\

   & \multicolumn{3}{c|}{\bf $<\multimap43\,181>$}   & \multicolumn{3}{c|}{\bf $<\multimap25\,709>$}   & \multicolumn{3}{c|}{\bf $<\multimap759\,734>$}   & \multicolumn{3}{c|}{\bf $<\multimap602\,539>$}   & \multicolumn{3}{c|}{\bf $<\multimap1\,843\,811>$}\\

   & \multicolumn{3}{c|}{\bf $|E|=1\,049\,866$}   & \multicolumn{3}{c|}{\bf $|E|=925\,872$}   & \multicolumn{3}{c|}{\bf $|E|=2\,278\,852$}   & \multicolumn{3}{c|}{\bf $|E|=2\,987\,624$}   & \multicolumn{3}{c|}{\bf $|E|=5\,021\,410$}\\ \hline

   \textbf{~~~~~met}     & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ \\\hline

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\multicolumn{1}{c}{}& \multicolumn{15}{c}{} \\ \hline
& $\bf 96$ & $\bf 40$ & $\bf 57$ & $\bf 81$ & $\bf 40$ & $\bf 53$ & $\bf 35$ & $\bf 15$ & $\bf 21$ & $\bf 62$ & $\bf 18$ & $\bf 28$ & $\bf 26$ & $\bf 5$ & $\bf 9$ \\

\textbf{$B^{0.30}$}& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.30}:~74 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.30}:~67 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.30}:~27 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.30}:~41 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.30}:~15 \rangle$ } \\
& \multicolumn{3}{c|}{$[143\,005; 74\,287]$}& \multicolumn{3}{c|}{$[143\,381; 81\,201]$}& \multicolumn{3}{c|}{$[769\,620; 79\,409]$}& \multicolumn{3}{c|}{$[647\,177; 244\,839]$}& \multicolumn{3}{c|}{$[2\,243\,002; 66\,328]$} \\
% & \multicolumn{3}{c|}{$(659s)$}& \multicolumn{3}{c|}{$(731s)$}& \multicolumn{3}{c|}{$(8\,127s)$}& \multicolumn{3}{c|}{$(8\,615s)$}& \multicolumn{3}{c|}{$(66\,909s)$} \\ \hline
& \multicolumn{3}{c|}{$(659s)$}& \multicolumn{3}{c|}{$(731s)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 78$ & $\bf 47$ & $\bf 59$ & $\bf 63$ & $\bf 52$ & $\bf 57$ & $\bf 23$ & $\bf 24$ & $\bf 23$ & $\bf 41$ & $\bf 23$ & $\bf 29$ & $\bf 13$ & $\bf 8$ & $\bf 10$ \\

\textbf{$B^{0.50}$}& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.50}:~59 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.50}:~57 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.50}:~23 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.50}:~29 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.50}:~10 \rangle$ } \\
& \multicolumn{3}{c|}{$[110\,572; 63\,979]$}& \multicolumn{3}{c|}{$[99\,830; 68\,640]$}& \multicolumn{3}{c|}{$[574\,168; 78\,148]$}& \multicolumn{3}{c|}{$[499\,570; 206\,340]$}& \multicolumn{3}{c|}{$[2\,102\,765; 56\,596]$} \\
% & \multicolumn{3}{c|}{$(664s)$}& \multicolumn{3}{c|}{$(739s)$}& \multicolumn{3}{c|}{$(8\,219s)$}& \multicolumn{3}{c|}{$(8\,686s)$}& \multicolumn{3}{c|}{$(67\,058s)$} \\ \hline
& \multicolumn{3}{c|}{$(664s)$}& \multicolumn{3}{c|}{$(739s)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 47$ & $\bf 58$ & $\bf 52$ & $\bf 42$ & $\bf 64$ & $\bf 51$ & $\bf 13$ & $\bf 37$ & $\bf 19$ & $\bf 23$ & $\bf 29$ & $\bf 26$ & $\bf 6$ & $\bf 13$ & $\bf 8$ \\

\textbf{$B^{0.70}$}& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.70}:~55 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.70}:~58 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.70}:~27 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.70}:~27 \rangle$ }& \multicolumn{3}{c|}{$\langle \EuScript{F}_{0.70}:~10 \rangle$ } \\
& \multicolumn{3}{c|}{$[61\,342; 43\,956]$}& \multicolumn{3}{c|}{$[56\,561; 47\,322]$}& \multicolumn{3}{c|}{$[274\,001; 74\,138]$}& \multicolumn{3}{c|}{$[354\,773; 147\,994]$}& \multicolumn{3}{c|}{$[1\,882\,873; 46\,418]$} \\
% & \multicolumn{3}{c|}{$(675s)$}& \multicolumn{3}{c|}{$(746s)$}& \multicolumn{3}{c|}{$(8\,369s)$}& \multicolumn{3}{c|}{$(8\,768s)$}& \multicolumn{3}{c|}{$(67\,329s)$} \\ \hline
& \multicolumn{3}{c|}{$(675s)$}& \multicolumn{3}{c|}{$(746s)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$}& \multicolumn{3}{c|}{$(!)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\multicolumn{1}{c}{}& \multicolumn{15}{c}{} \\ \hline
& $\bf 99$ & $\bf 42$ & $\bf 59$ & $\bf 90$ & $\bf 37$ & $\bf 52$ & $\bf 42$ & $\bf 13$ & $\bf 20$ & $\bf 63$ & $\bf 18$ & $\bf 28$ & $\bf 27$ & $\bf 6$ & $\bf 9$ \\

\textbf{$B2^{0.30}$}& \multicolumn{3}{c|}{$\langle F_{0.30}:77 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:69 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:29 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:42 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:15 \rangle$ } \\
& \multicolumn{3}{c|}{$[149939; 71974]$}& \multicolumn{3}{c|}{$[160431; 81969]$}& \multicolumn{3}{c|}{$[839308; 74970]$}& \multicolumn{3}{c|}{$[672965; 222911]$}& \multicolumn{3}{c|}{$[2268294; 64422]$} \\
& \multicolumn{3}{c|}{$(5s)$}& \multicolumn{3}{c|}{$(4s)$}& \multicolumn{3}{c|}{$(18s)$}& \multicolumn{3}{c|}{$(98s)$}& \multicolumn{3}{c|}{$(644s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 82$ & $\bf 48$ & $\bf 61$ & $\bf 67$ & $\bf 51$ & $\bf 58$ & $\bf 25$ & $\bf 22$ & $\bf 23$ & $\bf 41$ & $\bf 24$ & $\bf 30$ & $\bf 14$ & $\bf 8$ & $\bf 10$ \\

\textbf{$B2^{0.50}$}& \multicolumn{3}{c|}{$\langle F_{0.50}:61 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:58 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:23 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:30 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:10 \rangle$ } \\
& \multicolumn{3}{c|}{$[115340; 68121]$}& \multicolumn{3}{c|}{$[107351; 67874]$}& \multicolumn{3}{c|}{$[644731; 72683]$}& \multicolumn{3}{c|}{$[557701; 192483]$}& \multicolumn{3}{c|}{$[2122955; 55169]$} \\
& \multicolumn{3}{c|}{$(6s)$}& \multicolumn{3}{c|}{$(4s)$}& \multicolumn{3}{c|}{$(27s)$}& \multicolumn{3}{c|}{$(141s)$}& \multicolumn{3}{c|}{$(686s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 52$ & $\bf 58$ & $\bf 55$ & $\bf 44$ & $\bf 65$ & $\bf 52$ & $\bf 13$ & $\bf 35$ & $\bf 19$ & $\bf 22$ & $\bf 31$ & $\bf 26$ & $\bf 6$ & $\bf 13$ & $\bf 8$ \\

\textbf{$B2^{0.70}$}& \multicolumn{3}{c|}{$\langle F_{0.70}:56 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:59 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:26 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:29 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:10 \rangle$ } \\
& \multicolumn{3}{c|}{$[69970; 49250]$}& \multicolumn{3}{c|}{$[63373; 47332]$}& \multicolumn{3}{c|}{$[358767; 67960]$}& \multicolumn{3}{c|}{$[427653; 147255]$}& \multicolumn{3}{c|}{$[1898536; 45225]$} \\
& \multicolumn{3}{c|}{$(9s)$}& \multicolumn{3}{c|}{$(5s)$}& \multicolumn{3}{c|}{$(49s)$}& \multicolumn{3}{c|}{$(417s)$}& \multicolumn{3}{c|}{$(901s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\multicolumn{1}{c}{}& \multicolumn{15}{c}{} \\ \hline
& $\bf 0$ & $\bf 84$ & $\bf 0$ & $\bf 0$ & $\bf 94$ & $\bf 0$ & $\bf 0$ & $\bf 74$ & $\bf 0$ & $\bf 0$ & $\bf 84$ & $\bf 0$ & $\bf 0$ & $\bf 68$ & $\bf 0$ \\

\textbf{$Louv$}& \multicolumn{3}{c|}{$[207; 207]$}& \multicolumn{3}{c|}{$[237; 237]$}& \multicolumn{3}{c|}{$[430; 430]$}& \multicolumn{3}{c|}{$[6\,878; 6\,878]$}& \multicolumn{3}{c|}{$[6\,074; 6\,074]$} \\
& \multicolumn{3}{c|}{(8s)}& \multicolumn{3}{c|}{(3s)}& \multicolumn{3}{c|}{(14s)}& \multicolumn{3}{c|}{(13s)}& \multicolumn{3}{c|}{(31s)} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{tabular}
\bigskip
    \caption{{\bf Compare the performances of $BEC.2$ against $Louvain$ as a time baseline and $BEC$ as a quality baseline.}
    $precision$, $recall$ and $\EuScript{F}_{\sigma}$ are multiplied by 100;
    $<\multimap x>$ for $\Big|\Big\{i\in V \text{ such } \big|\big\{\{i,j\} \in E\big\}\big|=1 \Big\}\Big|=x$;
    $B$ for $BEC$;
    $B2$ for $BEC.2$;
    $Louv$ for $Louvain$;
    $\langle \EuScript{F}_{x}:~y \rangle$ for $\EuScript{F}_{x}(met(G),G)=y$;
    $[x; y]$ for $|met(G)|=x$ and $|\{\mathcal{C}_i \in met(G) \text{ such } |\mathcal{C}_i|>1\}|=y$;
    (xs) for x is the computation time in seconds of $met(G)$ and $(!)$ if it took over one hour to run.
    \label{PerfTerrain}}
\end{table}
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\normalsize

In this section we compare the performances on five terrain graphs:
\begin{itemize}
    \item {\bf $\bf G_{DBLP}$:} The DBLP computer science bibliography provides a comprehensive list of research papers in computer science \cite{snapnets}. Two authors are connected if they have published at least one paper together. \url{https://snap.stanford.edu/data/com-DBLP.html}.
    %
    \item {\bf $\bf G_{Amazon}$:} A Graph was collected by crawling the Amazon website. It is based on the {\it Customers Who Bought This Item Also Bought} feature of the Amazon website \cite{snapnets}. If a product $i$ is frequently co-purchased with product $j$, the Graph contains an undirected edge $\{i,j\}$. \url{https://snap.stanford.edu/data/com-Amazon.html}.
    %
    \item {\bf $\bf G_{retwwet}$:} Nodes are twitter users and edges are retweets. These were collected from various social and political hashtags. \url{https://networkrepository.com/rt-retweet-crawl.php}.
    %
    \item {\bf $\bf G_{youtube}$:} Youtube is a video-sharing web site that includes a social network. The dataset contains a list of all of the user-to-user links. \url{https://networkrepository.com/soc_youtube_snap.php}.
    %
    \item {\bf $\bf G_{WikiTalk}$:} Nodes in the network represent Wikipedia users \cite{Leskovec2010SignedNI} and a directed edge from node i to node j represents that user i at least once edited a talk page of user j, then the graph is symmetrized. \url{https://snap.stanford.edu/data/wiki-Talk.html}.
 \end{itemize}

 \noindent
{\bf $\blacksquare$ We can see in Tab. \ref{PerfTerrain}} that $BEC.2$, performs the same or better than $BEC$ and is $\sim100$ times faster than it, but still remains slower than $Louvain$. It should be noted that:
\begin{itemize}
 \item $Louvain$ returns few modules strongly favorizing $recall$ at the cost of a very large degradation of $precision$ (always $P \approx 0$ on these five graphs);
 \item $BEC.2$ returns a lot of modules, it is because when there are many nodes with one alone neighbor in a graph
 (e.g., as we can see in Tab. \ref{PerfTerrain}, $G_{WikiTalk}$ has $2\,516\,783$ nodes, however it has  $1\,843\, 811$ nodes with only one neighbor.) then these nodes are often isolated in their own modules by $BEC.2$ in order to best optimize $\EuScript{F}_{\sigma}$.
\end{itemize}

\subsection{Evaluation on artificial graphs\label{SubSecEvalAG}}

\subsubsection{Evaluation on Random graph\label{SubSubSecEvalRG}}
\begin{figure}[ht!] \centering %% OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK
  {\includegraphics[width=3cm] {fig/figRDG/LegendeRDG_1.pdf.png}}~~~~
  {\includegraphics[width=2.6cm] {fig/figRDG/Legende_2.pdf.png}}~~~~
  {\includegraphics[width=3cm] {fig/figRDG/Legende_3.pdf.png}}\\
  \vspace{0.20cm}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figRDG/FIGRDG-AgainstEdges-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figRDG/FIGRDG-AgainstEdges-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figRDG/FIGRDG-AgainstEdges-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figRDG/FIGRDG-AgainstEdges-F.pdf}}
  %==========================================================================================================
   \caption{{\bf Performance with $Benchmark_{ER}$.} In these four figures, for each point $(x=p,y)$ of each of the 8 curves per figure, $y$ is the average over $100$ random graphs $G^{N=128}_{x=p}$.
   For each point $(x=p, y)$ of the $|\mathcal{C}|$ curves, the standard deviation of $y$ is always lower than $3$. \label{A_FIG_RDG_AgainstEdges_p}}
  %===========================================================================================================
\end{figure}

$Benchmark_{ER}$ is the class of Random graphs studied by Erd\"os and R\'enyi \cite{Erdos:1959:pmd,Erdos:1960} with parameters $N$ the number of nodes and $p$ the connection probability between two nodes.
%
Random graphs do not have meaningful group structures, and they can be used to test if the algorithms are able to recognize the absence of group structures. An algorithm is able to recognize the absence of group structures in a random graph $G^N_p$ if its returned clustering $\mathcal{C}$ is such that $|\mathcal{C}|=1$ or $|\mathcal{C}|=N$.
%
Therefore, we set $N=128$ and we will study the accuracy of the methods with $Benchmark_{ER}$ according to $p$.

\vspace{0.20cm}
\noindent
Let $G_{ER}=(V_{ER},E_{ER})$ a random graph built by $Benchmark_{ER}$, $\Gamma_{ER}=\{V\}$ with only one cluster,
and $Oracle_{ER}(G_{ER})=\Gamma_{ER}=\{V\}$ the Oracle's method who knows $\Gamma_{ER}=\{V\}$ but ignores $E_{ER}$ the concretly constructed edges.

\noindent
We show in Fig. \ref{A_FIG_RDG_AgainstEdges_p} the accuracy of the methods according to $p$.
We can see that:
\begin{itemize}
  \item $\bf Oracle_{ER}:$ It knows $\Gamma_{ER}=\{V\}$, but does not know the concretely constructed edges $E_{ER}$.
    Its numbers of clusters are always $=1$.
    Its $precision$ scores increases when $p$ increases, because $density$ increases.
    Its $recall$ scores are always $=1$.
    Its $\EuScript{F}_{\sigma=0.5}$ scores increase;

  \item $\bf Louvain:$ $|Louvain(G_p)|=1$ only when $p=1$, it therefore does not recognize the absence of group structures in Random Graphs;

 \item $\bf BEC^{s}:$ When $p$ is large enough, they returns one alone cluster $\{V\}$, thus recognizing the absence of group structures in Random Graphs. The larger $s$, the less $p$ needs to be large to they recognize the absence of group structure;

 \item $\bf BEC.2^{s}:$ Same as $BEC^{s}$. To they recognize the absence of group structure, $p$ needs to be more large than for $BEC^{s}$;
\end{itemize}

\subsection{Evaluation on $Benchmark_{LFR}$\label{SubSubSecEvalLFR}}
In order to allow to systematically study the behavior of clustering methods relative to the complex nature of the community structure in real networks,
Lancichinetti, Fortunato and Radicchi proposed $Benchmark_{LFR}$ \cite{Lancichinetti2008Benchmark}.
The graphs $G^{N,k,a,b,on,om}_{\mu}$ in $Benchmark_{LFR}$ are parameterized \footnote{Code to generate $Benchmark_{LFR}$ graphs can be downloaded from Andrea Lancichinetti's homepage \url{https://sites.google.com/site/andrealancichinetti/home}.} with:
\begin{itemize}
 \item $N$ their number of nodes;
 \item $k$ their average degree;
 \item $a$ the power law exponent of their degree distribution;
 \item $b$ the power law exponent  of their community sizes distribution;
 \item $\mu \in [0,1]$ their mixing parameter: Each node shares a fraction $1 - \mu$ of its links with
the other nodes of its community and a fraction $\mu$
with the other nodes of the graph.
 \item $on$ the number of overlapping nodes;
 \item $om$ the number of memberships of the overlapping nodes.
\end{itemize}
%
With $Benchmark_{LFR}$, when the mixing parameter $\mu$ is weak, the overconnected regions are well separated from each other,
and when $\mu$ increases, the overconnected regions are less clear.

\begin{figure}[H] \centering %% OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK
  {\includegraphics[width=3cm] {fig/figLFR_NO/LegendeLFR_1.pdf.png}}~~~~
  {\includegraphics[width=2.6cm] {fig/figLFR_NO/Legende_2.pdf.png}}~~~~
  {\includegraphics[width=3cm] {fig/figLFR_NO/Legende_3.pdf.png}}\\
  \vspace{0.20cm}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb1.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb1.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb1.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb1.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb2.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb2.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb2.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta2.00-tb2.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta3.00-tb1.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta3.00-tb1.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta3.00-tb1.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k15-maxk50-ta3.00-tb1.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %===========================================================================================================
    \caption{{\bf Performance with $Benchmark^{NO}_{LFR}$ ($\bf k=15$).}
    In these $12$ figures, for each point $(x=\mu,y)$ of each of the $8$ curves per figure, $y$ is the average over $100$ graphs $G^{N=1000,k=15,on=0,om=0,a,b}_{x=\mu}$.
    For each point $(x=\mu, y)$ of the $F_{\sigma=0.5}$ curves the standard deviation of $y$ is always lower than $0.05$.\label{FIG_NO15_LFR_AgainstEdges}}
  %===========================================================================================================
\end{figure}
\begin{figure}[H] \centering %% OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK
  {\includegraphics[width=3cm] {fig/figLFR_OV/LegendeLFR_1.pdf.png}}~~~~
  {\includegraphics[width=2.6cm] {fig/figLFR_NO/Legende_2.pdf.png}}~~~~
  {\includegraphics[width=3cm] {fig/figLFR_NO/Legende_3.pdf.png}}\\
  \vspace{0.20cm}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb1.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb1.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb1.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb1.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb2.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb2.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb2.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta2.00-tb2.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta3.00-tb1.00-on0-om0-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta3.00-tb1.00-on0-om0-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta3.00-tb1.00-on0-om0-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_NO/BEC2_FIGLFRAgainstEdgesN1000-k25-maxk50-ta3.00-tb1.00-on0-om0-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %===========================================================================================================
    \caption{{\bf Performance with $Benchmark^{NO}_{LFR}$ ($\bf k=25$).}
    In these $12$ figures, for each point $(x=\mu,y)$ of each of the $8$ curves per figure, $y$ is the average over $100$ graphs $G^{N=1000,k=25,on=0,om=0,a,b}_{x=\mu}$.
    For each point $(x=\mu, y)$ of the $F_{\sigma=0.5}$ curves the standard deviation of $y$ is always lower than $0.05$.\label{FIG_NO25_LFR_AgainstEdges}}
  %===========================================================================================================
\end{figure}
\begin{figure}[H] \centering %% OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK
  {\includegraphics[width=3cm] {fig/figLFR_OV/LegendeLFR_1.pdf.png}}~~~~
  {\includegraphics[width=2.6cm] {fig/figLFR_OV/Legende_2.pdf.png}}~~~~
  {\includegraphics[width=3cm] {fig/figLFR_OV/Legende_3.pdf.png}}\\
  \vspace{0.20cm}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb1.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb1.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb1.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb1.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb2.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb2.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb2.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta2.00-tb2.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta3.00-tb1.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta3.00-tb1.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta3.00-tb1.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k15-maxk30-ta3.00-tb1.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %===========================================================================================================
    \caption{{\bf Performance with $Benchmark^{OV}_{LFR}$ ($\bf k=15$).}
    In these $12$ figures, for each point $(x=\mu,y)$ of each of the $8$ curves per figure, $y$ is the average over $100$ graphs $G^{N=200,k=15,on=100,om=4,a,b}_{x=\mu}$.
    For each point $(x=\mu, y)$ of the $\EuScript{F}_{\sigma=0.5}$ curves the standard deviation of $y$ is always lower than $0.05$.\label{FIG_OV15_LFR_AgainstEdges}}
  %===========================================================================================================
\end{figure}
\begin{figure}[H] \centering %% OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK
  {\includegraphics[width=3cm] {fig/figLFR_OV/LegendeLFR_1.pdf.png}}~~~~
  {\includegraphics[width=2.6cm] {fig/figLFR_OV/Legende_2.pdf.png}}~~~~
  {\includegraphics[width=3cm] {fig/figLFR_OV/Legende_3.pdf.png}}\\
  \vspace{0.20cm}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb1.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb1.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb1.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb1.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb2.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb2.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb2.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta2.00-tb2.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta3.00-tb1.00-on100-om4-NbM.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta3.00-tb1.00-on100-om4-P.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta3.00-tb1.00-on100-om4-R.pdf}}
  {\includegraphics[width=3.9cm]{fig/figLFR_OV/BEC2_FIGLFRAgainstEdgesN200-k25-maxk30-ta3.00-tb1.00-on100-om4-F.pdf}}\\
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %===========================================================================================================
    \caption{{\bf Performance with $Benchmark^{OV}_{LFR}$ ($\bf k=25$).}
    In these $12$ figures, for each point $(x=\mu,y)$ of each of the $8$ curves per figure, $y$ is the average over $100$ graphs $G^{N=200,k=25,on=100,om=4,a,b}_{x=\mu}$.
    For each point $(x=\mu, y)$ of the $\EuScript{F}_{\sigma=0.5}$ curves the standard deviation of $y$ is always lower than $0.05$.\label{FIG_OV25_LFR_AgainstEdges}}
  %===========================================================================================================
\end{figure}
\paragraph{Performance on $Benchmark^{NO}_{LFR}$ without overlaps: \label{PerfBenchLFRWout}}

We set $on=0$, $om=0$, $N=1000$, and $k=15$ or $k=25$, $(a=2, b=1)$ or $(a=2, b=2)$ or $(a=3, b=1)$
and for each of these six configurations, we study the accuracy of the methods according to $\mu$.

\vspace{0.20cm}
\noindent
Let $G^{NO}_{LFR}=(V^{NO}_{LFR},E^{NO}_{LFR})$ a graph built by $Benchmark^{NO}_{LFR}$,
$\Gamma^{NO}_{LFR}$ its expected modules as expected overconnected regions,
and $Oracle^{NO}_{LFR}(G^{NO}_{LFR})=\Gamma^{NO}_{LFR}$ the Oracle's method which knows $\Gamma^{NO}_{LFR}$ but ignores $E^{NO}_{LFR}$ the concretly constructed edges.
%
We show in Fig. \ref{FIG_NO15_LFR_AgainstEdges} and \ref{FIG_NO25_LFR_AgainstEdges} the accuracy of the methods according to $\mu$.
We can see that:

\begin{itemize}

    \item $\bf Oracle^{NO}_{LFR}:$ It knows $\Gamma^{NO}_{LFR}$, but does not know the concretely constructed edges $E^{NO}_{LFR}$.
    Its number of clusters is always $|\Gamma^{NO}_{LFR}|$.
    Its $precision$ scores decreases when $\mu$ increase, because there are more and more non-edges in the expected modules, but $Oracle^{NO}_{LFR}$ does not know it.
    Its $recall$ scores decreases when $\mu$ increase, because there are more and more edges outside the expected modules, but $Oracle^{NO}_{LFR}$ does not know it.
    Its $\EuScript{F}_{\sigma=0.5}$ scores decreases when $\mu$ increase;

    \item $\bf Louvain:$ Always $\EuScript{F}_{\sigma=0.5}(Louvain(G_{\mu}), G_{\mu})$ $\leqslant$ $\EuScript{F}_{\sigma=0.5}(Oracle^{NO}_{LFR},G_{\mu})$ and often its $\EuScript{F}_{\sigma=0.5}$ scores are the lowest of the eight methods studied here;

    \item $\bf BEC^{s}:$ Always $\EuScript{F}_{\sigma=0.5}(Oracle^{NO}_{LFR},G_{\mu})$ $\leqslant$ $\EuScript{F}_{\sigma=0.5}(BEC^{s=0.5}(G_{\mu}), G_{\mu})$;

    \item $\bf BEC.2^{s}:$ Always $\EuScript{F}_{\sigma=0.5}(BEC^{s=0.5}(G_{\mu}), G_{\mu})$ $\leqslant$ $\EuScript{F}_{\sigma=0.5}(BEC.2^{s=0.5}(G_{\mu}), G_{\mu})$;

\end{itemize}

\color{black}
\paragraph{Performance on $Benchmark^{OV}_{LFR}$ with overlaps: \label{PerfBenchLFRWit}}

We set $on=100$ and $om=4$, $N=200$, and $k=15$ or $k=25$, $(a=2, b=1)$ or $(a=2, b=2)$ or $(a=3, b=1)$
and for each of these six configurations, study the accuracy of the methods according to $\mu$.

\vspace{0.20cm}
\noindent
Let $G^{OV}_{LFR}=(V^{OV}_{LFR},E^{OV}_{LFR})$ a graph built by $Benchmark^{OV}_{LFR}$,
$\Gamma^{OV}_{LFR}$ its expected modules as expected overconnected regions,
and $Oracle^{OV}_{LFR}(G^{OV}_{LFR})=\Gamma^{OV}_{LFR}$ the Oracle's method which knows $\Gamma^{OV}_{LFR}$ but ignores $E^{OV}_{LFR}$ the concretly constructed edges.
%
We show in Fig. \ref{FIG_OV15_LFR_AgainstEdges} and \ref{FIG_OV25_LFR_AgainstEdges} the accuracy of the methods according to $\mu$.
We can see that:

\color{black}
\begin{itemize}

    \item $\bf Oracle^{OV}_{LFR}:$ It knows $\Gamma^{OV}_{LFR}$, but does not know the concretely constructed edges $E^{OV}_{LFR}$.
    Its number of clusters is always $|\Gamma^{OV}_{LFR}|$.
    Its $precision$ decreases when $\mu$ increase, because there are more and more non-edges in the expected modules, but $Oracle^{OV}_{LFR}$ does not know it.
    Its $recall$ decreases when $\mu$ increase, because there are more and more edges outside the expected modules, but $Oracle^{OV}_{LFR}$ does not know it.
    Its $\EuScript{F}_{\sigma=0.5}$ decreases when $\mu$ increase;

    \item $\bf Louvain:$ [When overconnected regions are {\bf clear}, $\EuScript{F}_{\sigma=0.5}$ are low]; [When overconnected regions are {\bf less clear}, $\EuScript{F}_{\sigma=0.5}$ are better than that of $Oracle^{OV}_{LFR}$];

    \item $\bf BEC^{s}:$ [When overconnected regions are {\bf clear}, $\EuScript{F}_{\sigma=0.5}$ are low]; [When overconnected regions are {\bf less clear}, $\EuScript{F}_{\sigma=0.5}$ are better than that of $Oracle^{OV}_{LFR}$];

    \item $\bf BEC.2^{s}:$ [When overconnected regions are {\bf clear}, $\EuScript{F}_{\sigma=0.5}$ are low]; [When overconnected regions are {\bf less clear}, $\EuScript{F}_{\sigma=0.5}$ are better than that of $Oracle^{OV}_{LFR}$].
    %
    Always $\EuScript{F}_{\sigma=0.5}(Louvain(G_{\mu}), G_{\mu})$ $\leqslant$ $\EuScript{F}_{\sigma=0.5}(BEC.2^{s=0.5}(G_{\mu}), G_{\mu})$.
    %
    Always $\EuScript{F}_{\sigma=0.5}(BEC^{s=0.5}(G_{\mu}), G_{\mu})$ $\leqslant$ $\EuScript{F}_{\sigma=0.5}(BEC.2^{s=0.5}(G_{\mu}), G_{\mu})$.
\end{itemize}

\subsection{Computation times and sapce memory  \label{Calculation_times}}

In Tab. \ref{TC} we show the computation times for each method on the $19\,005$ graphs used for evaluation of the methods
in the section \ref{SecEval}.
We can see that $BEC.2$ is approximately $100$ times faster than $BEC$ while it is approximately $10$ to $20$ times slower than $Louvain$ (depending of $s$ the desired scale of description).

On the other hand, to cluster a graph $G=(V,E)$, in the worst case, the memory space occupied by $Louvain$ and $BEC.2$ is $O(E)$, and it is $O(V^2)$ by $BEC$ (because the computaion of the similarities $cos(G=(V,E), x, y)$ for all $\{x,y\} \in E$). Since in general terrain graphs are sparse where $E$ is $O(|V|.log(|V|))$, the memory space required for $Louvain$ and $BEC.2$ is therefore in general less than for $BEC$.

\begin{table}[!ht]
\footnotesize
\centering
\begin{tabular}{|l | c | c  | c  | c | c |  }
\hline
  &{\bf $\bf Terrain$} & {\bf $\bf Bench_{ER}$} & {\bf $\bf Bench_{LFR}^{NO}$} & {\bf $\bf Bench_{LFR}^{OV}$} & {\bf $\bf Total$} \\
  &{\bf $\bf [5]$} & {\bf $\bf [1\,000]$} & {\bf $\bf [9\,000]$} & {\bf $\bf [9\,000]$} & {\bf $\bf [19\,005]$} \\
\hline
\hline
\color{red}         {\bf $\bf Louvain$}& \color{red} $69$        & \color{red} $2$  & \color{red} $49$     & \color{red} $12$  & \color{red} $\bf 132$ \\
\hline
\hline
  {\bf $\bf BEC^{s=0.30}$}& $85\,041$   & $31$ & $1\,026$ & $167$ & $\bf 86\,265$ \\
\hline
  {\bf $\bf BEC^{s=0.50}$}& $85\,366$   & $23$ & $1\,368$ & $289$ & $\bf 87\,046$ \\
\hline
  {\bf $\bf BEC^{s=0.70}$}& $85\,887$   & $26$ & $3\,177$ & $646$ & $\bf 89\,736$ \\
\hline
\hline
  {\bf $\bf BEC.2^{s=0.30}$}& $769$       & $5$  & $271$    & $37$  & $\bf 1\,082$ \\
\hline
  {\bf $\bf BEC.2^{s=0.50}$}& $864$       & $5$  & $328$    & $58$ & $\bf 1\,255$ \\
\hline
  {\bf $\bf BEC.2^{s=0.70}$}& $1\,381$    & $1$  & $629$    & $127$ & $\bf 2\,138$ \\
\hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{tabular}
\bigskip
    \caption{{\bf Computaion times in seconds.} $[x]$ for $x$ is the number of graphs in the concerned categories.
    \label{TC}}
\end{table}
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\normalsize

\section{Clustering with overlaps \label{SecOverlaps}}
$\forall G=(V,E) \in \mathcal{G}(V)$, then $E \in \EuScript{C}(V)$, $\EuScript{P}(E,G)=\EuScript{R}(E,G)=1$ and
generaly $E$ is an overlaping clustering such $|V| < |E|$.
%
To enable us to find an overlapping clustering $\mathcal{C}_o$ of a graph $G=(V,E)$ such $|\mathcal{C}_o| \leqslant |V|$, we propose below the Algorithm $OVP.ind_{s_{o}}(G, \mathcal{C}_{p})$ which is based on gluantly extending the clusters of a partitional clustering $\mathcal{C}_{p}$ through the optimization of $\EuScript{F}_{s_{o}}(\mathcal{C}_p, G)$ with the stickiness scale $s_{o}$ defining the desired amount of overlap.

It is clear that $|\mathcal{C}_{o}| \leqslant |\mathcal{C}_{p}| \leqslant |V|$ (because \texttt{{(Line$\bf_1$)}} and $\mathcal{C}_{p}$ is a partitional clustering).
Moreover
$\forall s_{o} \in [0,1], {\Xi}(\mathcal{C}_{p}) \subseteq {\Xi}(\mathcal{C}_{o})$ (because we only add nodes to the clusters of $\mathcal{C}_{p}$).
This has the direct consequence: $ \forall~s_{o} \in [0,1],~\EuScript{R}(\mathcal{C}_{p}, G) \leqslant \EuScript{R}(\mathcal{C}_{o}, G)$.

In the following we will note $BEC.2^{s_p}_{s_o}$ for $OVP.ind_{s_o}(G, \mathcal{C}_{p}=BEC.2^{s_p}(G))$.

For example with the graph $G_{toy}$ in Tab. \ref{tigraph}:

\begin{itemize}
 \item $\mathcal{C}_{p}=BEC.2^{0.6}(G_{toy})=\big\{\{0, 2, 3\}, \{1, 4, 5\}\big\}:$
 $\EuScript{P}(\mathcal{C}_{p}, G)=1.00,$
 $\EuScript{R}(\mathcal{C}_{p}, G)=0.86,$
 $\EuScript{F}_{0.5}(\mathcal{C}_{p}, G)=0.92,$
 $\EuScript{F}_{0.6}(\mathcal{C}_{p}, G)=0.90$;

 \item $\mathcal{C}_{o}=BEC.2^{0.6}_{0.6}(G_{toy})=\big\{\{0, 2, 3\}, \{0, 1, 4, 5\}\big\}:$
 $\EuScript{P}(\mathcal{C}_{o}, G)=0.78,$
 $\EuScript{R}(\mathcal{C}_{o}, G)=1.00,$
 $\EuScript{F}_{0.5}(\mathcal{C}_{o}, G)=0.88,$
 $\EuScript{F}_{0.6}(\mathcal{C}_{o}, G)=0.91$;
\end{itemize}

\noindent
\rule{16cm}{0.05cm}

\noindent{\bf Algorithm: $\mathcal{C}_{o} = OVP.ind_{s_o}(G, \mathcal{C}_{p})$:} To gluantly extend the clusters of $\mathcal{C}_{p}$

\vspace{-0.2cm}
\noindent
\rule{16cm}{0.025cm}

\noindent
{\bf Input:} $G = (V, E) \in \EuScript{G}(V)$

\noindent
\hspace{1.3cm}$s_o \in [0, 1]$

\noindent
\hspace{1.3cm}$\mathcal{C}_{p}$ A partitional clustering of $G$

\noindent
{\bf Output:}  $\mathcal{C}_{o} \in \EuScript{C}(V)$
\begin{itemize}
 \item[{\bf }] {\bf Initialization:}  $\mathcal{C} \leftarrowtail \mathcal{C}_{p}$;

 \item[] {\bf Loop on $\bf i \in V$:} For each node $i$:
  \vspace{-0.20cm}
 \begin{itemize}
 \item[] {\bf Add Loop on neighbors of $\bf i$:} For each neighbor $j$ of $i$, improve the curent clustering $\mathcal{C}$ by adding $i$ to the cluster of $j$. If it cannot improve $\EuScript{F}_{s_o}(\mathcal{C},G)$ then we examine the next neighbor of $i$;
\end{itemize}

  \item[] $\bf \mathcal{C}_{o} \leftarrowtail \{ C_i \in \mathcal{C} \text{ such } \nexists C_j \in \mathcal{C} ~|~C_i \varsubsetneq C_j \}$
  $\blacktriangleright$ \texttt{{\bf (Line$\bf_1$)}}

 \item[{\bf }] {\bf Return:} Return $\mathcal{C}_{o}$.
\end{itemize}
\vspace{-0.5cm}
\noindent
\rule{16cm}{0.025cm}

Fig \ref{FigPrecRecPlane_email_Overlaps} and \ref{FigScaleFamily_email_Overlaps} compare the performances of
$BEC.2^{s}$ and
$BEC.2^{s}_{s}$ on the the email graph $G_{em}$
and Table \ref{PerfTerrainOVP} on the same five terrain graphs as those in Table \ref{PerfTerrain}.

\noindent
{\bf $\blacksquare$ We can see in Fig. \ref{FigPrecRecPlane_email_Overlaps}} that
$\EuScript{R}\big(BEC.2^{s}(G_{em}),G_{em}\big) \leqslant \EuScript{R}\big(BEC.2^{s}_{s}(G_{em}),G_{em}\big)$.

\noindent
{\bf $\blacksquare$ We can see in Fig. \ref{FigScaleFamily_email_Overlaps}} $\EuScript{F_{\sigma}}\big(BEC.2^{\sigma}(G_{em}),G_{em}\big) \leqslant$ $\EuScript{F_{\sigma}}\big(BEC.2^{\sigma}_{\sigma}(G_{em}),G_{em}\big)$.

\noindent
{\bf $\blacksquare$ We can see in Tab. \ref{PerfTerrainOVP}} that for these five terrain graphs,
$\EuScript{R}\big(BEC.2^{s}(G),G\big) < \EuScript{R}\big(BEC.2^{s}_{s}(G),G\big)$
and $\EuScript{F}_{\sigma}\big(BEC.2^{\sigma}(G),G\big) < $ $\EuScript{F}_{\sigma}\big(BEC.2^{\sigma}_{\sigma}(G),G\big)$.

\newpage
\begin{figure}[h!] \centering
     \includegraphics[width=16cm]{fig/BEC2_FigPrecRecPlane_email+square_Overlaps.png}
 %===========================================================================================================
 \caption{{\bf Performances in the $\bf 2$-dimensional space $\bf precision\times recall$ of  $\bf BEC.2~^{s_p}$ and $\bf BEC.2~^{s_p}_{s_p}$ when applied to the e-mail graph $\bf G_{em}$.} The Oracle method $met_{Dep}$ and the Omniscient method $met_E$ are highligthed in red.
    \label{FigPrecRecPlane_email_Overlaps}}
 \end{figure}

\newpage
\begin{figure}[h!] \centering
     \includegraphics[width=16cm]{fig/BEC2_FigScaleFamily_email_Overlaps.png}
 %===========================================================================================================
\caption{{\bf Performances $\bf \EuScript{F}_{\sigma}(\clubsuit,G_{em})$ of clustering methods
$\bf method(G_{em})=\clubsuit$ under the description scale $\bf \sigma$.}
The Oracle method $met_{Dep}$ and the Omniscient method $met_E$ are highligthed in red.
    \label{FigScaleFamily_email_Overlaps}}
\end{figure}

\newpage
\begin{table}[!ht]
\small
\centering
\begin{tabular}{| l | c c c  | c c c | c c c | c c c | c c c | }
   \hline   & \multicolumn{3}{c|}{\bf $\bf G_{dblp}$}   & \multicolumn{3}{c|}{\bf $\bf G_{amazon}$}   & \multicolumn{3}{c|}{\bf $\bf G_{retweet}$}   & \multicolumn{3}{c|}{\bf $\bf G_{youtube}$}   & \multicolumn{3}{c|}{\bf $\bf G_{WikiTalk}$}\\

   %& \multicolumn{3}{c|}{\bf $|V|=317\,080$}   & \multicolumn{3}{c|}{\bf $|V|=334\,863$}   & \multicolumn{3}{c|}{\bf $|V|=1\,112\,702$}   & \multicolumn{3}{c|}{\bf $|V|=1\,134\,890$}   & \multicolumn{3}{c|}{\bf $|V|=2\,516\,783$}\\

   %& \multicolumn{3}{c|}{\bf $<\multimap43\,181>$}   & \multicolumn{3}{c|}{\bf $<\multimap25\,709>$}   & \multicolumn{3}{c|}{\bf $<\multimap759\,734>$}   & \multicolumn{3}{c|}{\bf $<\multimap602\,539>$}   & \multicolumn{3}{c|}{\bf $<\multimap1\,843\,811>$}\\

   %& \multicolumn{3}{c|}{\bf $|E|=1\,049\,866$}   & \multicolumn{3}{c|}{\bf $|E|=925\,872$}   & \multicolumn{3}{c|}{\bf $|E|=2\,278\,852$}   & \multicolumn{3}{c|}{\bf $|E|=2\,987\,624$}   & \multicolumn{3}{c|}{\bf $|E|=5\,021\,410$}\\ \hline

   \textbf{~~~~~met}     & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ & $\bf P$ & $\bf R$ &  $\bf \EuScript{F}_{0.5}$ \\\hline

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\multicolumn{1}{c}{}& \multicolumn{15}{c}{} \\ \hline
& $\bf 99$ & $\bf 42$ & $\bf 59$ & $\bf 90$ & $\bf 37$ & $\bf 52$ & $\bf 42$ & $\bf 13$ & $\bf 20$ & $\bf 63$ & $\bf 18$ & $\bf 28$ & $\bf 27$ & $\bf 6$ & $\bf 9$ \\

\textbf{$B2^{0.30}$}& \multicolumn{3}{c|}{$\langle F_{0.30}:77 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:69 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:29 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:42 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:15 \rangle$ } \\
%& \multicolumn{3}{c|}{$[149939; 71974]$}& \multicolumn{3}{c|}{$[160431; 81969]$}& \multicolumn{3}{c|}{$[839308; 74970]$}& \multicolumn{3}{c|}{$[672965; 222911]$}& \multicolumn{3}{c|}{$[2268294; 64422]$} \\
& \multicolumn{3}{c|}{$(5s)$}& \multicolumn{3}{c|}{$(4s)$}& \multicolumn{3}{c|}{$(18s)$}& \multicolumn{3}{c|}{$(98s)$}& \multicolumn{3}{c|}{$(644s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 82$ & $\bf 48$ & $\bf 61$ & $\bf 67$ & $\bf 51$ & $\bf 58$ & $\bf 25$ & $\bf 22$ & $\bf 23$ & $\bf 41$ & $\bf 24$ & $\bf 30$ & $\bf 14$ & $\bf 8$ & $\bf 10$ \\

\textbf{$B2^{0.50}$}& \multicolumn{3}{c|}{$\langle F_{0.50}:61 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:58 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:23 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:30 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:10 \rangle$ } \\
%& \multicolumn{3}{c|}{$[115340; 68121]$}& \multicolumn{3}{c|}{$[107351; 67874]$}& \multicolumn{3}{c|}{$[644731; 72683]$}& \multicolumn{3}{c|}{$[557701; 192483]$}& \multicolumn{3}{c|}{$[2122955; 55169]$} \\
& \multicolumn{3}{c|}{$(6s)$}& \multicolumn{3}{c|}{$(4s)$}& \multicolumn{3}{c|}{$(27s)$}& \multicolumn{3}{c|}{$(141s)$}& \multicolumn{3}{c|}{$(686s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 52$ & $\bf 58$ & $\bf 55$ & $\bf 44$ & $\bf 65$ & $\bf 52$ & $\bf 13$ & $\bf 35$ & $\bf 19$ & $\bf 22$ & $\bf 31$ & $\bf 26$ & $\bf 6$ & $\bf 13$ & $\bf 8$ \\

\textbf{$B2^{0.70}$}& \multicolumn{3}{c|}{$\langle F_{0.70}:56 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:59 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:26 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:29 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:10 \rangle$ } \\
%& \multicolumn{3}{c|}{$[69970; 49250]$}& \multicolumn{3}{c|}{$[63373; 47332]$}& \multicolumn{3}{c|}{$[358767; 67960]$}& \multicolumn{3}{c|}{$[427653; 147255]$}& \multicolumn{3}{c|}{$[1898536; 45225]$} \\
& \multicolumn{3}{c|}{$(9s)$}& \multicolumn{3}{c|}{$(5s)$}& \multicolumn{3}{c|}{$(49s)$}& \multicolumn{3}{c|}{$(417s)$}& \multicolumn{3}{c|}{$(901s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\multicolumn{1}{c}{}& \multicolumn{15}{c}{} \\ \hline
& $\bf 99$ & $\bf 81$ & $\bf 89$ & $\bf 92$ & $\bf 64$ & $\bf 75$ & $\bf 68$ & $\bf 55$ & $\bf 61$ & $\bf 71$ & $\bf 45$ & $\bf 55$ & $\bf 71$ & $\bf 60$ & $\bf 65$ \\

\textbf{$B2^{0.30}_{0.30}$}& \multicolumn{3}{c|}{$\langle F_{0.30}:95 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:84 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:65 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:64 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.30}:68 \rangle$ } \\
%& \multicolumn{3}{c|}{$[149939; 149938]$}& \multicolumn{3}{c|}{$[160431; 160429]$}& \multicolumn{3}{c|}{$[839308; 839308]$}& \multicolumn{3}{c|}{$[672965; 672963]$}& \multicolumn{3}{c|}{$[2268294; 2268294]$} \\
& \multicolumn{3}{c|}{$(1s)$}& \multicolumn{3}{c|}{$(1s)$}& \multicolumn{3}{c|}{$(3s)$}& \multicolumn{3}{c|}{$(10s)$}& \multicolumn{3}{c|}{$(62s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 80$ & $\bf 86$ & $\bf 83$ & $\bf 66$ & $\bf 81$ & $\bf 72$ & $\bf 39$ & $\bf 59$ & $\bf 47$ & $\bf 47$ & $\bf 58$ & $\bf 52$ & $\bf 45$ & $\bf 68$ & $\bf 54$ \\

\textbf{$B2^{0.50}_{0.50}$}& \multicolumn{3}{c|}{$\langle F_{0.50}:83 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:72 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:47 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:52 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.50}:54 \rangle$ } \\
%& \multicolumn{3}{c|}{$[115340; 115339]$}& \multicolumn{3}{c|}{$[107351; 107342]$}& \multicolumn{3}{c|}{$[644731; 644731]$}& \multicolumn{3}{c|}{$[557701; 557700]$}& \multicolumn{3}{c|}{$[2122955; 2122955]$} \\
& \multicolumn{3}{c|}{$(1s)$}& \multicolumn{3}{c|}{$(1s)$}& \multicolumn{3}{c|}{$(4s)$}& \multicolumn{3}{c|}{$(25s)$}& \multicolumn{3}{c|}{$(135s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
& $\bf 47$ & $\bf 93$ & $\bf 62$ & $\bf 39$ & $\bf 91$ & $\bf 55$ & $\bf 16$ & $\bf 64$ & $\bf 26$ & $\bf 22$ & $\bf 74$ & $\bf 34$ & $\bf 20$ & $\bf 72$ & $\bf 31$ \\

\textbf{$B2^{0.70}_{0.70}$}& \multicolumn{3}{c|}{$\langle F_{0.70}:77 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:72 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:40 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:50 \rangle$ }& \multicolumn{3}{c|}{$\langle F_{0.70}:47 \rangle$ } \\
%& \multicolumn{3}{c|}{$[69970; 69966]$}& \multicolumn{3}{c|}{$[63373; 63362]$}& \multicolumn{3}{c|}{$[358767; 358767]$}& \multicolumn{3}{c|}{$[427653; 427653]$}& \multicolumn{3}{c|}{$[1898536; 1898536]$} \\
& \multicolumn{3}{c|}{$(1s)$}& \multicolumn{3}{c|}{$(2s)$}& \multicolumn{3}{c|}{$(8s)$}& \multicolumn{3}{c|}{$(72s)$}& \multicolumn{3}{c|}{$(316s)$} \\ \hline
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{tabular}
\bigskip
    \caption{{\bf Compare the performances of $BEC.2^{s_p}(G)$ and $BEC.2^{s_p}_{s_o}(G)$.}
    $precision$, $recall$ and $\EuScript{F}_{\sigma}$ are multiplied by 100;
    %$<\multimap x>$ for $\Big|\Big\{i\in V \text{ such } \big|\big\{\{i,j\} \in E\big\}\big|=1 \Big\}\Big|=x$;
    $B2$ for $BEC.2$;
    $\langle \EuScript{F}_{x}:~y \rangle$ for $\EuScript{F}_{x}(met(G),G)=y$;
    (xs) for x is the computation time in seconds of $met(G)$.
    \label{PerfTerrainOVP}}
\end{table}
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
% @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\normalsize

\section{Conclusion\label{Conclusion}}
\begin{itemize}
\item[(1)] It is shown in the recent paper \cite{Gaume_BEC1_2025} that in the $nPnB$ framework, $BEC$ outperforms most state-of-the-art methods (including $spectral~graph~clustering$, one of the best efficient state-of-the-art methods);
\item[(2)] We showed in section \ref{SecEval} that in the $nPnB$ framework, $BEC.2$ outperforms $BEC$.
\end{itemize}

\noindent
(1) \& (2) imply that in the $nPnB$ framework, $BEC.2$ outperforms most state-of-the-art methods, i.e. better satisfying the two properties $P_{DC}$ and $P_{WC}$:

\hspace{1cm}$\bf P_{DC}:$ Each community is {\it Densely Connected}; \vspace{-0.10cm}

\hspace{1cm}$\bf P_{WC}:$  Communities are {\it Weakly Connected} to each other.

From physical sciences to biological or social sciences, complex systems are defined as large sets of entities interacting in a decentralized ways. Graphs are one of the main conceptual structures for modeling them, where nodes represent the basic lowest-level entities and edges represent their interactions.
%
$BEC.2^{s_p}_{s_o}(G)$ is a kind of telescope for observing the graphs modeling complex systems, where $s_p$ defines the desired scale of description of the modules as highest-level entities and $s_o$ the level of overlap of these entities.
%
$BEC.2$ is $10$ to $20$ times slower than $Louvain$ but is $100$ times faster than $BEC$, which allows working with large graphs in reasonable time.

\subsection{Perspectives\label{Perspectives}}

\paragraph{Gain speed:} $BEC.2$ remains slower than $Louvain$, define a high-performance algorithm in the $nPnB$ framework, as fast as $Louvain$ should be part of further developements.

\vspace{-0.50cm}
\paragraph{Directed weighted edges and temporal dimension:}
Many complex networks have directed weighted edges and have a temporal dimension wich are not been addressed with $BEC.2$ and should be part of further developements.

\vspace{-0.50cm}
\paragraph{Attributed graph clustering:}
When nodes of the graph also have some attributes, it is possible to define clusterings that take these attributes into account  (see for exemple  \cite{cao_knowledge_2024, BERAHMAND2024127041, he2021survey, berahmand2023dac, berahmand2024sdac, su2022comprehensive, chunaev2020community, wang2022deep}). Attributed graph clustering  can be perfectly hybridised with $BEC.2$, but it will still be necessary to assess beforehand the relative weight given to the information contained in the links and that contained in the attributes of the nodes and should be part of further developements.

\vspace{-0.50cm}
\paragraph{Intrinsic description scales:}
The values $s_i$ maximizing $\EuScript{F}_{0.5}(BEC.2_{s_i}^{s_i}(G),BEC.2^{s_i}(G))$ can help define the {\it intrinsic description scales} of $G$ and its {\it intrinsic ground truths}
without overlaps $\mathcal{C}^{s_i}=BEC.2^{s_i}(G)$ or with overlaps $\mathcal{C}^{s_i}_{s_i}=BEC.2_{s_i}^{s_i}(G)$
(see \cite{Gaume_BEC1_2025, Ronhovde_2009}).
The search for such $s_i$ with short computation time should be the subject of further developments.

% \vspace{-0.50cm}
% \paragraph{Graph compression:}
% Applications to graph compression could also be useful.
% %
% For example, let a simple entropy encoder $ec$ \cite{shannon_1948} based on Huffman coding \cite{Huffman_1952} or Arithmetic coding  \cite{Arithmetic_Coding_1979} and a graph $G=(V,E)$, the losslessly description length \cite{grunwald2007minimum} of the graph is then $dl(ec(G))$.
% %
% To lossily compress the graph, we could use $\mathcal{C}^s_s=BEC.2_s^s(G)$ with $ec(\mathcal{C}^s_s)$ and its decompressed graph $\reallywidehat{\mathcal{C}^s_s}=\big(V_{s}=U(\mathcal{C}^s_s), E_{s}=\Xi(\mathcal{C}^s_s)\big)$ where always $V_s=V$ but generaly $E_{s} \neq E$.
% If $s > 0.5$, then the loss will be primarily due to false positives (the set $E_s^- = \Xi(\mathcal{C}^s_s) \cap \overline{E}$ of the edges present in the graph $\reallywidehat{\mathcal{C}^s_s}$ but absent in $G$),
% whereas if $s < 0.5$ then the loss will be mainly due to false negatives (the set $E_s^+ = E \cap  \overline{\Xi(\mathcal{C}^s_s)}$ of the missing edges in the graph $\reallywidehat{\mathcal{C}^s_s}$). The lossily description length of the graph is then $dl(ec(\mathcal{C}^s_s))$,
% with a lossily compression ratio $\tau(s,G)=\frac{dl(ec(G))}{dl(ec(\mathcal{C}^s_s))}$.
% %
% If we want to losslessly compress the graph $G$, we must then jointly add to $\mathcal{C}^s_s$ the set
% $E_s^+$ and the set $E_s^-$, in order to be able to reconstruct from
% ($\mathcal{C}^s_s$, $E_s^+$, $E_s^-$) the graph $G = (V = U(\mathcal{C}^s_s), E = (\Xi(\mathcal{C}^s_s) \cap \overline{E_s^-}) \cup E_s^+)$.
% The losslessly compression ratio is then $\tau(s,G)=\frac{dl(ec(G))}{dl(ec((\mathcal{C}^s_s, E_s^+, E_s^-)))}$.
% %
% In order to maximize the losslessly compression ratio,
% the scale of description $s$ must be determined so that the value $dl(ec((\mathcal{C}^s_s, E_s^+, E_s^-)))$
% is minimal. The search for such $s$ with short computation time should be the subject of further developments.
%


% Many complex networks have directed weighted edges wich are not been addressed wit $BEC.2$ and should be part of further developements.
%
% Applications to graph compression could also be useful.
% For example,
% $\mathcal{C}_s=BEC.2_s^s(G)$ could be used to lossily compress the graph $G$.
% If $s > 0.5$, then the loss will be primarily due to false positives (edges present in the graph $\reallywidehat{\mathcal{C}_s}$ but absent in $G$),
% whereas if $s < 0.5$ then the loss will be mainly due to false negatives (missing edges in the graph $\reallywidehat{\mathcal{C}_s}$).
% The compression ratio $\tau(s,G)$ is then $O(\frac{2|E|}{\sum_{C_i \in \mathcal{C}_s}|C_i|})$.
%
% % %We can then use an entropy encoder to translates $\mathcal{C}_s$ into bits \cite{shannon_1948,Huffman_1952}.
%
% If we want to losslessly compress the graph $G$, we must then jointly add to $\mathcal{C}_s$
% the set $E_s^+ = E \cap  \overline{\Xi(\mathcal{C}_s)}$ of false negatives
% and the set $E_s^- = \Xi(\mathcal{C}_s) \cap \overline{E}$ of false positives, in order to be able to reconstruct from
% ($\mathcal{C}_s$, $E_s^+$, $E_s^-$) the graph $G = (V = U(\mathcal{C}_s), E = (\Xi(\mathcal{C}_s) \cap \overline{E_s^-}) \cup E_s^+)$.
% %
% In order to maximize the lossless compression ratios
% $\tau(s,G)= \frac{2|E|}{\big(\sum_{C_i \in \mathcal{C}_s}|C_i|\big) + 2\big(|E_s^+| + |E_s^-|\big)}$
% the scales of description $s$ must be determined so that the values
% $\big(\sum_{C_i \in \mathcal{C}_s}|C_i|\big) + 2\big(|E_s^+| + |E_s^-|\big)$
% are minimal.
% %
% % Similarly, maximizing $\EuScript{F}_{0.5}(BEC.2_s^s(G),BEC.2^s(G))$ can help define the intrinsic description scales of $G$ (see \cite{Gaume_BEC1_2025, Ronhovde_2009}).



\subsection*{Data availability}
The code is available at https://github.com/Brngm/nPnB.BEC2.

\subsection*{Funding}
%\vspace{-0.30cm}
This work was supported by the Complex Systems Institute of Paris Île-de-France (ISC-PIF) and the EU NODES project (LC-01967516).


\newpage
\bibliographystyle{siam}
\bibliography{bib_WoWo.bib}
\end{document}

